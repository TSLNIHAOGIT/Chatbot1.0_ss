{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-14T15:41:20.429630Z",
     "start_time": "2018-06-14T15:41:19.556111Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.450 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "from textblob import TextBlob\n",
    "from textblob.translate import NotTranslated\n",
    "from multiprocessing import Pool\n",
    "from itertools import repeat\n",
    "\n",
    "import jieba\n",
    "jieba.load_userdict(\"../WordCut/userdict.txt\")\n",
    "\n",
    "import gc\n",
    "\n",
    "model_list = ['CutDebt','IDClassifier','IfKnowDebtor','Installment','SetDueDay','WillingToPay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-14T15:41:21.811890Z",
     "start_time": "2018-06-14T15:41:21.711872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this part combine the data which can be used together.\n",
    "for each_model in model_list:\n",
    "    path = '../../data/{}/'\n",
    "    data = pd.read_csv(path.format(each_model) + 'mock_up_data1.csv', encoding='utf8')\n",
    "    data.to_csv(path.format(each_model) + 'combined_mock_up_data.csv', index = False, encoding = 'utf8')\n",
    "\n",
    "# label 0 part for CutDebt and Installment\n",
    "data_cut = pd.read_csv(path.format('CutDebt') + 'combined_mock_up_data.csv', encoding = 'utf8')\n",
    "data_ins = pd.read_csv(path.format('Installment') + 'combined_mock_up_data.csv', encoding = 'utf8')\n",
    "temp_cut = data_cut[data_cut.label == 0]\n",
    "temp_ins = data_ins[data_ins.label == 0]\n",
    "data_cut = pd.concat([data_cut,temp_ins], ignore_index=True)\n",
    "data_ins = pd.concat([data_ins,temp_cut], ignore_index=True)\n",
    "data_cut.to_csv(path.format('CutDebt') + 'combined_mock_up_data.csv', index = False, encoding = 'utf8')\n",
    "data_cut.to_csv(path.format('Installment') + 'combined_mock_up_data.csv', index = False, encoding = 'utf8')\n",
    "\n",
    "del data_cut\n",
    "del data_ins\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-14T15:41:24.257856Z",
     "start_time": "2018-06-14T15:41:24.209033Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate(comment, from_lang, to_lang):\n",
    "        if hasattr(comment, \"decode\"):\n",
    "            comment = comment.decode(\"utf-8\")\n",
    "\n",
    "        text = TextBlob(comment)\n",
    "        try:\n",
    "            text = text.translate(to=to_lang)\n",
    "            text = text.translate(to=from_lang)\n",
    "        except NotTranslated:\n",
    "            pass\n",
    "\n",
    "        return str(text)\n",
    "\n",
    "def translate_csv(df,col,from_lang,to_lang,num_pol=10):\n",
    "    \"\"\"\n",
    "        https://developers.google.com/translate/v2/using_rest#language-params\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    if num_pol >= 1000:\n",
    "        num_pol=1000\n",
    "    comment_pool = df[col].values\n",
    "    p = Pool(num_pol)\n",
    "    new_col_name = col + '_' + to_lang\n",
    "    df[new_col_name] = p.starmap(translate, zip(comment_pool, repeat(from_lang),repeat(to_lang)))\n",
    "    df = df.drop([col], axis = 1)\n",
    "    df = df.rename(index=str, columns={new_col_name:col})\n",
    "    return df\n",
    "\n",
    "def cut_words(text):\n",
    "    seg_list = jieba.cut(text, cut_all=False)\n",
    "    return \" \".join(seg_list)\n",
    "\n",
    "def clean(text):\n",
    "    text = re.sub(f'([{string.punctuation}“”¨«»®´·º ½¾¿¡§£₤‘’，])',' ', text)\n",
    "    text = text.split(' ')\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "def clean_label(label):\n",
    "    return int(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-14T15:48:25.733077Z",
     "start_time": "2018-06-14T15:41:28.509129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutDebt\n",
      "finish loading\n",
      "finish 1st trans\n",
      "finish 2nd trans\n",
      "finish 3rd trans\n",
      "finish 4th trans\n",
      "finish cutting words\n",
      "finish shuffling\n",
      "IDClassifier\n",
      "finish loading\n",
      "finish 1st trans\n",
      "finish 2nd trans\n",
      "finish 3rd trans\n",
      "finish 4th trans\n",
      "finish cutting words\n",
      "finish shuffling\n",
      "IfKnowDebtor\n",
      "finish loading\n",
      "finish 1st trans\n",
      "finish 2nd trans\n",
      "finish 3rd trans\n",
      "finish 4th trans\n",
      "finish cutting words\n",
      "finish shuffling\n",
      "Installment\n",
      "finish loading\n",
      "finish 1st trans\n",
      "finish 2nd trans\n",
      "finish 3rd trans\n",
      "finish 4th trans\n",
      "finish cutting words\n",
      "finish shuffling\n",
      "SetDueDay\n",
      "finish loading\n",
      "finish 1st trans\n",
      "finish 2nd trans\n",
      "finish 3rd trans\n",
      "finish 4th trans\n",
      "finish cutting words\n",
      "finish shuffling\n",
      "WillingToPay\n",
      "finish loading\n",
      "finish 1st trans\n",
      "finish 2nd trans\n",
      "finish 3rd trans\n",
      "finish 4th trans\n",
      "finish cutting words\n",
      "finish shuffling\n"
     ]
    }
   ],
   "source": [
    "for each_model in model_list:\n",
    "    print(each_model)\n",
    "    path = '../../data/{}/'\n",
    "    data = pd.read_csv(path.format(each_model) + 'combined_mock_up_data.csv', encoding='utf8')\n",
    "    data = data.dropna()\n",
    "    col = 'split_text'\n",
    "    print('finish loading')\n",
    "    \n",
    "    # translate and get more data\n",
    "    data_en = translate_csv(data,col,from_lang='zh',to_lang='en',num_pol=50)\n",
    "    print('finish 1st trans')\n",
    "    data_fr = translate_csv(data,col,from_lang='zh',to_lang='fr',num_pol=50)\n",
    "    print('finish 2nd trans')\n",
    "    data_th = translate_csv(data,col,from_lang='zh',to_lang='th',num_pol=50)\n",
    "    print('finish 3rd trans')\n",
    "    data_lo = translate_csv(data,col,from_lang='zh',to_lang='lo',num_pol=50)\n",
    "    print('finish 4th trans')\n",
    "    data = pd.concat([data,data_en,data_fr,data_th,data_lo], ignore_index=True)\n",
    "#     data = pd.concat([data,data_en,data_fr], ignore_index=True)\n",
    "    \n",
    "    # cut words\n",
    "    data['split_text']=data['split_text'].apply(cut_words)\n",
    "    print('finish cutting words')\n",
    "    \n",
    "    # cleaning and save\n",
    "    data['split_text'] = data['split_text'].apply(clean)\n",
    "    data['label'] = data['label'].apply(clean_label)\n",
    "\n",
    "    # shuffle data\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    print('finish shuffling')\n",
    "    data.to_csv(path.format(each_model) + 'cleaned_mock_up_data.csv', index = False, encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
