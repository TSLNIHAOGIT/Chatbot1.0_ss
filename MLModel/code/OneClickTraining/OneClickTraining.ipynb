{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T19:52:43.815936Z",
     "start_time": "2018-09-10T19:52:41.613103Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.826 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "sys.path.append('../../../Lib/')\n",
    "from load_cleaned_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T19:52:43.950142Z",
     "start_time": "2018-09-10T19:52:43.888965Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pickle\n",
    "\n",
    "import sys,os\n",
    "models_path = '../../../classifier/models/ml_models/'\n",
    "sys.path.append(models_path)\n",
    "from ml import *\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "model_list = {\n",
    "                'IDClassifier':IDClassifier, \n",
    "                  'CutDebt':CutDebt, \n",
    "                  'WillingToPay':WillingToPay,\n",
    "                  'IfKnowDebtor':IfKnowDebtor,\n",
    "                  'Installment':Installment,\n",
    "                  'ConfirmLoan':ConfirmLoan}\n",
    "\n",
    "\n",
    "def train_other_model(other_data,save_path,model):\n",
    "    phrase_vectorizer_other = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                strip_accents='unicode', \n",
    "                                max_features=100000, \n",
    "                                analyzer='word',\n",
    "                                sublinear_tf=True,\n",
    "                                token_pattern=r'\\w{1,}')\n",
    "\n",
    "    print('fitting phrase')\n",
    "    phrase_vectorizer_other.fit(other_data.text)\n",
    "\n",
    "    print('transform phrase')\n",
    "    phrase = phrase_vectorizer_other.transform(other_data.text)\n",
    "\n",
    "\n",
    "    # linear svc\n",
    "    l_svc = LinearSVC()\n",
    "    lsvc = CalibratedClassifierCV(l_svc) \n",
    "    lsvc.fit(phrase, other_data.label)\n",
    "\n",
    "\n",
    "    # logistic\n",
    "    log_r = LogisticRegression()\n",
    "    log_r.fit(phrase, other_data.label)\n",
    "\n",
    "\n",
    "    # Naive Bayes\n",
    "    naive_b = MultinomialNB()\n",
    "    naive_b.fit(phrase, other_data.label)\n",
    "    \n",
    "    print('finish training others')\n",
    "    \n",
    "    \n",
    "    # other wrapper \n",
    "    other_model = ClassifierOther(svc=lsvc, logistic=log_r, nb=naive_b, tfidf=phrase_vectorizer_other, jieba_path='../WordCut/userdict.txt',possible_label=lsvc.classes_)\n",
    "    \n",
    "    # Saving:\n",
    "    evl_path = save_path.format(model,model)\n",
    "    print('saving to path: {}'.format(evl_path))\n",
    "    pickle.dump(other_model, open(evl_path, \"wb\"))\n",
    "    return other_model\n",
    "    \n",
    "    \n",
    "def train_main_model(df,save_path,model,other_model):\n",
    "    # get tfidf\n",
    "    \n",
    "    phrase_vectorizer = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                    strip_accents='unicode', \n",
    "                                    max_features=100000, \n",
    "                                    analyzer='word',\n",
    "                                    sublinear_tf=True,\n",
    "                                    token_pattern=r'\\w{1,}')\n",
    "\n",
    "    print('fitting phrase')\n",
    "    phrase_vectorizer.fit(df.split_text)\n",
    "\n",
    "    print('transform phrase')\n",
    "    phrase = phrase_vectorizer.transform(df.split_text)\n",
    "    \n",
    "    # linear svc\n",
    "    l_svc = LinearSVC()\n",
    "    lsvc = CalibratedClassifierCV(l_svc) \n",
    "    lsvc.fit(phrase, df.label)\n",
    "    \n",
    "    \n",
    "    # logistic\n",
    "    log_r = LogisticRegression()\n",
    "    log_r.fit(phrase, df.label)\n",
    "    \n",
    "    \n",
    "    # Naive Bayes\n",
    "    naive_b = MultinomialNB()\n",
    "    naive_b.fit(phrase, df.label)\n",
    "    print('finish training')\n",
    "    \n",
    "    main_model = model_list[model](svc=lsvc, logistic=log_r, nb=naive_b, tfidf=phrase_vectorizer, other=other_model,  jieba_path='../WordCut/userdict.txt')\n",
    "    evl_path = save_path.format(model,model)\n",
    "    pickle.dump(main_model, open(evl_path, \"wb\"))\n",
    "    print('saving to path: {}'.format(evl_path))\n",
    "    return main_model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T19:52:59.346026Z",
     "start_time": "2018-09-10T19:52:44.033585Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 45.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutDebt\n",
      "finish cutting words\n",
      "1    1434\n",
      "0    1364\n",
      "Name: label, dtype: int64\n",
      "109    1376\n",
      "106     997\n",
      "104     907\n",
      "103     552\n",
      "108     355\n",
      "102     266\n",
      "107     133\n",
      "110      33\n",
      "Name: label, dtype: int64\n",
      "IDClassifier\n",
      "finish cutting words\n",
      "1    533\n",
      "0    339\n",
      "Name: label, dtype: int64\n",
      "109    1397\n",
      "104     952\n",
      "103     563\n",
      "107     366\n",
      "Name: label, dtype: int64\n",
      "IfKnowDebtor\n",
      "finish cutting words\n",
      "0    894\n",
      "1    519\n",
      "Name: label, dtype: int64\n",
      "109    1393\n",
      "104     952\n",
      "103     563\n",
      "107     365\n",
      "Name: label, dtype: int64\n",
      "Installment\n",
      "finish cutting words\n",
      "1    1368\n",
      "0    1364\n",
      "Name: label, dtype: int64\n",
      "109    1376\n",
      "106     998\n",
      "104     907\n",
      "103     553\n",
      "108     355\n",
      "102     277\n",
      "107     133\n",
      "110      33\n",
      "Name: label, dtype: int64\n",
      "WillingToPay\n",
      "finish cutting words\n",
      "1    1947\n",
      "0     669\n",
      "Name: label, dtype: int64\n",
      "109    1375\n",
      "106     988\n",
      "104     905\n",
      "103     551\n",
      "108     351\n",
      "102     334\n",
      "105     202\n",
      "107     133\n",
      "Name: label, dtype: int64\n",
      "ConfirmLoan\n",
      "finish cutting words\n",
      "0    1157\n",
      "1     609\n",
      "Name: label, dtype: int64\n",
      "109    1375\n",
      "104     900\n",
      "103     547\n",
      "108     344\n",
      "107     134\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training others\n",
      "saving to path: ../../../classifier/saved_model/IDClassifier/other_flow/IDClassifier.pkl\n",
      "=====  IDClassifier =======\n",
      "2    3278\n",
      "1     533\n",
      "0     339\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "saving to path: ../../../classifier/saved_model/IDClassifier/main_flow/IDClassifier.pkl\n",
      "\n",
      "\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training others\n",
      "saving to path: ../../../classifier/saved_model/CutDebt/other_flow/CutDebt.pkl\n",
      "=====  CutDebt =======\n",
      "2    4619\n",
      "1    1434\n",
      "0    1364\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "saving to path: ../../../classifier/saved_model/CutDebt/main_flow/CutDebt.pkl\n",
      "\n",
      "\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training others\n",
      "saving to path: ../../../classifier/saved_model/WillingToPay/other_flow/WillingToPay.pkl\n",
      "=====  WillingToPay =======\n",
      "2    4839\n",
      "1    1947\n",
      "0     669\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "saving to path: ../../../classifier/saved_model/WillingToPay/main_flow/WillingToPay.pkl\n",
      "\n",
      "\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training others\n",
      "saving to path: ../../../classifier/saved_model/IfKnowDebtor/other_flow/IfKnowDebtor.pkl\n",
      "=====  IfKnowDebtor =======\n",
      "2    3273\n",
      "0     894\n",
      "1     519\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "saving to path: ../../../classifier/saved_model/IfKnowDebtor/main_flow/IfKnowDebtor.pkl\n",
      "\n",
      "\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training others\n",
      "saving to path: ../../../classifier/saved_model/Installment/other_flow/Installment.pkl\n",
      "=====  Installment =======\n",
      "2    4632\n",
      "1    1368\n",
      "0    1364\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "saving to path: ../../../classifier/saved_model/Installment/main_flow/Installment.pkl\n",
      "\n",
      "\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training others\n",
      "saving to path: ../../../classifier/saved_model/ConfirmLoan/other_flow/ConfirmLoan.pkl\n",
      "=====  ConfirmLoan =======\n",
      "2    3300\n",
      "0    1157\n",
      "1     609\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "saving to path: ../../../classifier/saved_model/ConfirmLoan/main_flow/ConfirmLoan.pkl\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# each_model = 'IDClassifier' \n",
    "clean_data_main,clean_data_other = load_data(load_fb=True)\n",
    "save_path_other = '../../../classifier/saved_model/{}/other_flow/{}.pkl'\n",
    "save_path_main = '../../../classifier/saved_model/{}/main_flow/{}.pkl'\n",
    "for each_model in model_list:\n",
    "   \n",
    "\n",
    "    other_model = train_other_model(clean_data_other[each_model],save_path_other,each_model)\n",
    "    \n",
    "    df_main = clean_data_main[each_model].copy()\n",
    "    other_label = int(max(set(df_main.label)) + 1)\n",
    "    ava_others = clean_data_other[each_model].rename({'text':'split_text'},axis=1).copy()\n",
    "    ava_others['label'] = other_label\n",
    "    df_main = pd.concat([df_main,ava_others],sort=True)\n",
    "    df_main = df_main.sample(frac=1,random_state=6).reset_index(drop=True)\n",
    "    print('=====  {} ======='.format(each_model))\n",
    "    print(df_main.label.value_counts())\n",
    "    clf = train_main_model(df_main,save_path_main,each_model,other_model)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
