{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T18:36:59.243712Z",
     "start_time": "2018-07-30T18:36:58.492977Z"
    }
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "import pickle\n",
    "import sys,os\n",
    "from all_model_py import CutDebt, IDClassifier, IfKnowDebtor, Installment, WillingToPay, ConfirmLoan\n",
    "sys.path.append('../../../Lib/')\n",
    "from SUPPORT import balance_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T01:55:26.074734Z",
     "start_time": "2018-07-10T01:55:26.058361Z"
    }
   },
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T18:37:07.184704Z",
     "start_time": "2018-07-30T18:37:00.312848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutDebt :other label is 2\n",
      "=====  CutDebt =======\n",
      "2    4698\n",
      "0    3623\n",
      "1    2327\n",
      "Name: label, dtype: int64\n",
      "begin training!\n",
      "fitting phrase\n",
      "transform phrase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.751 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Zone is set from ENV: Asia/Shanghai\n",
      "IDClassifier :other label is 2\n",
      "=====  IDClassifier =======\n",
      "2    3486\n",
      "1    1234\n",
      "0    1133\n",
      "Name: label, dtype: int64\n",
      "begin training!\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "IfKnowDebtor :other label is 2\n",
      "=====  IfKnowDebtor =======\n",
      "2    3468\n",
      "0    1363\n",
      "1    1184\n",
      "Name: label, dtype: int64\n",
      "begin training!\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "Installment :other label is 2\n",
      "=====  Installment =======\n",
      "2    4703\n",
      "0    3623\n",
      "1    2379\n",
      "Name: label, dtype: int64\n",
      "begin training!\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "Time Zone is set from ENV: Asia/Shanghai\n",
      "ConfirmLoan :other label is 2\n",
      "=====  ConfirmLoan =======\n",
      "2    3345\n",
      "0     713\n",
      "1     548\n",
      "Name: label, dtype: int64\n",
      "begin training!\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "Time Zone is set from ENV: Asia/Shanghai\n",
      "WillingToPay :other label is 3\n",
      "=====  WillingToPay =======\n",
      "3    4576\n",
      "1    2620\n",
      "0    1778\n",
      "2    1038\n",
      "Name: label, dtype: int64\n",
      "begin training!\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "Time Zone is set from ENV: Asia/Shanghai\n"
     ]
    }
   ],
   "source": [
    "def get_other_data(df_non109,df_109,strategy_mat,classifier):\n",
    "    possible_label = sorted(list(set(strategy_mat[strategy_mat[classifier]==0]['label'].values)))\n",
    "    train_data_non109 = df_non109[df_non109['label'].apply(lambda x: x in possible_label)]\n",
    "    train_data_109 = df_109[df_109[classifier]==0]\n",
    "    data = pd.concat([train_data_non109,train_data_109],ignore_index=True,sort=True)\n",
    "    return data\n",
    "\n",
    "model_list = {'CutDebt':CutDebt,\n",
    "              'IDClassifier':IDClassifier,\n",
    "              'IfKnowDebtor':IfKnowDebtor,\n",
    "              'Installment':Installment,\n",
    "              'ConfirmLoan':ConfirmLoan,\n",
    "              'WillingToPay':WillingToPay}\n",
    "\n",
    "others_non109 = pd.read_csv('../../data/others/cleaned_mock_up_data_non109.csv')\n",
    "others_109 = pd.read_csv('../../data/others/cleaned_mock_up_data_109.csv')\n",
    "other_matrix = pd.read_csv('../../data/others/strategy_mat.csv')\n",
    "target = 'label'\n",
    "save_path = '../../savedModel/{}/'\n",
    "for model in model_list:\n",
    "    \n",
    "    df = pd.read_csv('../../data/{}/cleaned_mock_up_data.csv'.format(model))\n",
    "    other_label = int(max(set(df.label)) + 1)\n",
    "    print('{} :other label is {}'.format(model,other_label))\n",
    "    # filter out other label\n",
    "    # get availabel other labels\n",
    "    ava_others = get_other_data(others_non109,others_109,other_matrix,model)\n",
    "    ava_others = ava_others[['text','label']]\n",
    "    ava_others = ava_others.rename({'text':'split_text'},axis=1)\n",
    "    ava_others['label'] = other_label\n",
    "    df = pd.concat([df,ava_others],sort=True)\n",
    "    \n",
    "    df = df.sample(frac=1,random_state=6).reset_index(drop=True)\n",
    "    print('=====  {} ======='.format(model))\n",
    "    print(df.label.value_counts())\n",
    "    \n",
    "#     #################################### enable balancing\n",
    "#     print('enable balancing')\n",
    "#     df = balance_category(df,target='label')\n",
    "#     df = df.sample(frac=1).reset_index(drop=True)\n",
    "#     print(df.label.value_counts())\n",
    "#     print('!!!!!!!!!!!!!!!!!!')\n",
    "\n",
    "\n",
    "    print('begin training!')\n",
    "    \n",
    "    # get tfidf\n",
    "    phrase_vectorizer = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                    strip_accents='unicode', \n",
    "                                    max_features=100000, \n",
    "                                    analyzer='word',\n",
    "                                    sublinear_tf=True,\n",
    "                                    token_pattern=r'\\w{1,}')\n",
    "\n",
    "    print('fitting phrase')\n",
    "    phrase_vectorizer.fit(df.split_text)\n",
    "\n",
    "    print('transform phrase')\n",
    "    phrase = phrase_vectorizer.transform(df.split_text)\n",
    "    \n",
    "    # linear svc\n",
    "    l_svc = LinearSVC()\n",
    "    lsvc = CalibratedClassifierCV(l_svc) \n",
    "    lsvc.fit(phrase, df.label)\n",
    "    \n",
    "    \n",
    "    # logistic\n",
    "    log_r = LogisticRegression()\n",
    "    log_r.fit(phrase, df.label)\n",
    "    \n",
    "    \n",
    "    # Naive Bayes\n",
    "    naive_b = MultinomialNB()\n",
    "    naive_b.fit(phrase, df.label)\n",
    "    print('finish training')\n",
    "    \n",
    "    other = pickle.load(open('../../savedModel/others/{}/{}_other.pickle'.format(model,model),'rb'))\n",
    "    result = model_list[model](svc=lsvc, logistic=log_r, nb=naive_b, tfidf=phrase_vectorizer, other=other,  jieba_path='../WordCut/userdict.txt')\n",
    "    pickle.dump(result, open(save_path.format(model) + model + '.pickle', \"wb\"))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T19:27:41.141874Z",
     "start_time": "2018-07-17T19:27:40.652463Z"
    }
   },
   "outputs": [],
   "source": [
    "idc = pickle.load(open(\"../../savedModel/IDClassifier/IDClassifier.pickle\", 'rb'))\n",
    "# idc.warm_up()\n",
    "cutd = pickle.load(open(\"../../savedModel/CutDebt/CutDebt.pickle\", 'rb'))\n",
    "# cutd.warm_up()\n",
    "ifk = pickle.load(open(\"../../savedModel/IfKnowDebtor/IfKnowDebtor.pickle\", 'rb'))\n",
    "# ifk.warm_up()\n",
    "will = pickle.load(open(\"../../savedModel/WillingToPay/WillingToPay.pickle\", 'rb'))\n",
    "# will.warm_up()\n",
    "inst = pickle.load(open(\"../../savedModel/Installment/Installment.pickle\", 'rb'))\n",
    "# inst.warm_up()\n",
    "conf = pickle.load(open(\"../../savedModel/ConfirmLoan/ConfirmLoan.pickle\", 'rb'))\n",
    "# conf.warm_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T19:25:29.845456Z",
     "start_time": "2018-07-17T19:25:29.836244Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "jieba_path='../WordCut/userdict.txt'\n",
    "jieba.load_userdict(jieba_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T19:25:30.660433Z",
     "start_time": "2018-07-17T19:25:30.640018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我草'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = '我草'\n",
    "sentence = jieba.cut(sentence, cut_all = False)\n",
    "sentence = ' '.join(sentence)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T19:25:31.587313Z",
     "start_time": "2018-07-17T19:25:31.552970Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-17 19:25:31,555 - DEBUG - CLASS:IDClassifier- METHOD:classify -LINE:91 - MSG:In transfered tfidf, the number of words in vocalbulary is: 7\n",
      "2018-07-17 19:25:31,564 - DEBUG - CLASS:IDClassifier_other- METHOD:classify -LINE:54 - MSG:In transfered tfidf, the number of words in vocalbulary is: 7\n",
      "2018-07-17 19:25:31,569 - DEBUG - CLASS:IDClassifier_other- METHOD:classify -LINE:68 - MSG:Possible labels are: [101, 103, 104, 107, 109]\n",
      "2018-07-17 19:25:31,570 - DEBUG - CLASS:IDClassifier_other- METHOD:classify -LINE:69 - MSG:Other- Final Pred label is: 109\n",
      "2018-07-17 19:25:31,572 - DEBUG - CLASS:IDClassifier_other- METHOD:classify -LINE:70 - MSG:Other- svc,logistic,nb result:\n",
      " [[0.01229204 0.00878715 0.03084999 0.02068768 0.92738315]\n",
      " [0.04567845 0.07070934 0.11218043 0.08641978 0.68501199]\n",
      " [0.02678163 0.0659326  0.07371182 0.04837054 0.78520341]]\n",
      "2018-07-17 19:25:31,575 - DEBUG - CLASS:IDClassifier_other- METHOD:classify -LINE:71 - MSG:Other- ave result:\n",
      " [0.0282507  0.04847636 0.07224741 0.051826   0.79919952]\n",
      "2018-07-17 19:25:31,576 - DEBUG - CLASS:IDClassifier- METHOD:classify -LINE:110 - MSG:Final Pred label is: 109\n",
      "2018-07-17 19:25:31,578 - DEBUG - CLASS:IDClassifier- METHOD:classify -LINE:111 - MSG:svc,logistic,nb result:\n",
      " [[0.02966849 0.06300469 0.90732683]\n",
      " [0.08315464 0.12056887 0.79627649]\n",
      " [0.07769235 0.16328557 0.75902208]]\n",
      "2018-07-17 19:25:31,580 - DEBUG - CLASS:IDClassifier- METHOD:classify -LINE:112 - MSG:ave result:\n",
      " [0.06350516 0.11561971 0.82087513]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 109, 'pred_prob': array([[0.02966849, 0.06300469, 0.90732683],\n",
       "        [0.08315464, 0.12056887, 0.79627649],\n",
       "        [0.07769235, 0.16328557, 0.75902208]]), 'av_pred': array([0.06350516, 0.11561971, 0.82087513])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idc.classify('我日你大爷')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T19:25:35.786566Z",
     "start_time": "2018-07-17T19:25:35.737145Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-17 19:25:35,739 - DEBUG - CLASS:IfKnowDebtor- METHOD:classify -LINE:133 - MSG:In transfered tfidf, the number of words in vocalbulary is: 2\n",
      "2018-07-17 19:25:35,748 - DEBUG - CLASS:IfKnowDebtor_other- METHOD:classify -LINE:54 - MSG:In transfered tfidf, the number of words in vocalbulary is: 2\n",
      "2018-07-17 19:25:35,757 - DEBUG - CLASS:IfKnowDebtor_other- METHOD:classify -LINE:68 - MSG:Possible labels are: [101, 103, 104, 107, 109]\n",
      "2018-07-17 19:25:35,763 - DEBUG - CLASS:IfKnowDebtor_other- METHOD:classify -LINE:69 - MSG:Other- Final Pred label is: 109\n",
      "2018-07-17 19:25:35,766 - DEBUG - CLASS:IfKnowDebtor_other- METHOD:classify -LINE:70 - MSG:Other- svc,logistic,nb result:\n",
      " [[0.0129794  0.00927091 0.17834439 0.02584743 0.77355787]\n",
      " [0.04054026 0.06677474 0.2481428  0.06135361 0.58318859]\n",
      " [0.03837694 0.11028452 0.16092267 0.07497266 0.61544321]]\n",
      "2018-07-17 19:25:35,770 - DEBUG - CLASS:IfKnowDebtor_other- METHOD:classify -LINE:71 - MSG:Other- ave result:\n",
      " [0.0306322  0.06211006 0.19580328 0.0540579  0.65739655]\n",
      "2018-07-17 19:25:35,772 - DEBUG - CLASS:IfKnowDebtor- METHOD:classify -LINE:152 - MSG:Final Pred label is: 109\n",
      "2018-07-17 19:25:35,775 - DEBUG - CLASS:IfKnowDebtor- METHOD:classify -LINE:153 - MSG:svc,logistic,nb result:\n",
      " [[0.0878981  0.03684717 0.87525473]\n",
      " [0.18791168 0.06799357 0.74409475]\n",
      " [0.17459152 0.09840418 0.72700431]]\n",
      "2018-07-17 19:25:35,777 - DEBUG - CLASS:IfKnowDebtor- METHOD:classify -LINE:154 - MSG:ave result:\n",
      " [0.15013377 0.06774831 0.78211793]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 109, 'pred_prob': array([[0.0878981 , 0.03684717, 0.87525473],\n",
       "        [0.18791168, 0.06799357, 0.74409475],\n",
       "        [0.17459152, 0.09840418, 0.72700431]]), 'av_pred': array([0.15013377, 0.06774831, 0.78211793])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ifk.classify('我日')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T19:25:36.758755Z",
     "start_time": "2018-07-17T19:25:36.720318Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-17 19:25:36,727 - DEBUG - CLASS:ConfirmLoan- METHOD:_ext_time -LINE:55 - MSG:No time was extracted!\n",
      "2018-07-17 19:25:36,737 - DEBUG - CLASS:ConfirmLoan- METHOD:classify -LINE:183 - MSG:In transfered tfidf, the number of words in vocalbulary is: 7\n",
      "2018-07-17 19:25:36,741 - DEBUG - CLASS:ConfirmLoan- METHOD:classify -LINE:205 - MSG:Final Pred label is: 1\n",
      "2018-07-17 19:25:36,745 - DEBUG - CLASS:ConfirmLoan- METHOD:classify -LINE:206 - MSG:svc,logistic,nb result:\n",
      " [[0.00418647 0.85258438 0.14322914]\n",
      " [0.0697489  0.39089623 0.53935487]\n",
      " [0.09625575 0.56770718 0.33603707]]\n",
      "2018-07-17 19:25:36,749 - DEBUG - CLASS:ConfirmLoan- METHOD:classify -LINE:207 - MSG:ave result:\n",
      " [0.05673038 0.60372926 0.33954036]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 1, 'pred_prob': array([[0.00418647, 0.85258438, 0.14322914],\n",
       "        [0.0697489 , 0.39089623, 0.53935487],\n",
       "        [0.09625575, 0.56770718, 0.33603707]]), 'av_pred': array([0.05673038, 0.60372926, 0.33954036]), 'time_extract': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.classify('我只借过5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T19:25:54.614870Z",
     "start_time": "2018-07-17T19:25:54.599210Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-17 19:25:54,601 - DEBUG - CLASS:WillingToPay- METHOD:_ext_time -LINE:58 - MSG:More than 2 times were extracted!\n",
      "2018-07-17 19:25:54,603 - DEBUG - CLASS:WillingToPay- METHOD:classify -LINE:248 - MSG:There are more than 1 time extracted. And the min -0.43183358 is shorter than lower bounder! The output label is set to 10!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 10,\n",
       " 'pred_prob': 1.0,\n",
       " 'av_pred': 1.0,\n",
       " 'time_extract': [{'pattern': '下个星期三',\n",
       "   'time': datetime.datetime(2018, 7, 25, 19, 0, tzinfo=<DstTzInfo 'America/New_York' EDT-1 day, 20:00:00 DST>),\n",
       "   'gapS': 689645.399112,\n",
       "   'gapH': 191.56816642},\n",
       "  {'pattern': '今天下午',\n",
       "   'time': datetime.datetime(2018, 7, 17, 19, 0, tzinfo=<DstTzInfo 'America/New_York' EDT-1 day, 20:00:00 DST>),\n",
       "   'gapS': -1554.600888,\n",
       "   'gapH': -0.43183358}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "will.classify('我下个星期三还不行，今天下午可以')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:31:59.269501Z",
     "start_time": "2018-07-17T18:31:59.234756Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "import sys,os\n",
    "tpattern_path = '../TimePattern/'\n",
    "others_pth = '../Others/'\n",
    "ENV_PATH = '../../../ENV/'\n",
    "LOG_PATH = '../../../Lib/'\n",
    "\n",
    "sys.path.append( tpattern_path)\n",
    "from  time_pattern import TimePattern\n",
    "t = TimePattern(pattern_path=tpattern_path+'mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:32:05.933232Z",
     "start_time": "2018-07-17T18:32:05.918133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pattern': '下周',\n",
       "  'time': datetime.datetime(2018, 7, 24, 16, 0, tzinfo=<DstTzInfo 'America/New_York' EDT-1 day, 20:00:00 DST>),\n",
       "  'gapS': 595674.080177,\n",
       "  'gapH': 165.4650222713889},\n",
       " {'pattern': '周三',\n",
       "  'time': datetime.datetime(2018, 7, 18, 16, 0, tzinfo=<DstTzInfo 'America/New_York' EDT-1 day, 20:00:00 DST>),\n",
       "  'gapS': 77274.080177,\n",
       "  'gapH': 21.46502227138889}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.process('下周周三')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:32:00.249168Z",
     "start_time": "2018-07-17T18:32:00.240815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pattern': '周三',\n",
       "  'time': datetime.datetime(2018, 7, 18, 16, 0, tzinfo=<DstTzInfo 'America/New_York' EDT-1 day, 20:00:00 DST>),\n",
       "  'gapS': 77279.756818,\n",
       "  'gapH': 21.46659911611111}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.process('周三')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
