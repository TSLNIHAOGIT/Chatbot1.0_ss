{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T17:16:34.288446Z",
     "start_time": "2018-07-18T17:16:33.406480Z"
    }
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "# import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "import sys,os\n",
    "sys.path.append('../../MLModel/code/OneClickTraining/')\n",
    "from all_model_py import CutDebt, IDClassifier, IfKnowDebtor, Installment, WillingToPay, ConfirmLoan\n",
    "\n",
    "sys.path.append('../../Lib/')\n",
    "from model_matrix import eval_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T17:16:41.840430Z",
     "start_time": "2018-07-18T17:16:41.835994Z"
    }
   },
   "outputs": [],
   "source": [
    "def sub_df(df,sets,target='label'):\n",
    "    result = pd.DataFrame()\n",
    "    for each in sets:\n",
    "        result = pd.concat([result,df[df[target]==each]])\n",
    "#     print(result[target].value_counts())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T17:17:15.273640Z",
     "start_time": "2018-07-18T17:17:15.233753Z"
    }
   },
   "outputs": [],
   "source": [
    "others = pd.read_csv('../../MLModel/data/others/cleaned_mock_up_data.csv')\n",
    "other_matrix = pd.read_csv('../../MLModel/data/others/strategy_mat.csv')\n",
    "target = 'label'\n",
    "save_path = '../../MLModel/savedModel/{}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CutDebt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T17:17:17.532565Z",
     "start_time": "2018-07-18T17:17:17.524444Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_list = {'CutDebt':CutDebt,\n",
    "              'IDClassifier':IDClassifier,\n",
    "              'IfKnowDebtor':IfKnowDebtor,\n",
    "              'Installment':Installment,\n",
    "              'ConfirmLoan':ConfirmLoan,\n",
    "              'WillingToPay':WillingToPay}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T17:17:36.050976Z",
     "start_time": "2018-07-18T17:17:28.954559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====  Installment =======\n",
      "2    4228\n",
      "0    4105\n",
      "1    2034\n",
      "Name: label, dtype: int64\n",
      "begin training!\n",
      "fitting phrase\n",
      "transform phrase\n",
      "======== Linear SVC =======\n",
      "                pred_0      pred_1       pred_2    recall\n",
      "actual_0   1073.000000   52.000000   120.000000  0.861847\n",
      "actual_1     87.000000  394.000000   121.000000  0.654485\n",
      "actual_2     94.000000   90.000000  1080.000000  0.854430\n",
      "precision     0.855662    0.735075     0.817562  0.818708\n",
      "======== logistic =======\n",
      "                pred_0      pred_1      pred_2    recall\n",
      "actual_0   1037.000000   42.000000   166.00000  0.832932\n",
      "actual_1     85.000000  361.000000   156.00000  0.599668\n",
      "actual_2     94.000000   64.000000  1106.00000  0.875000\n",
      "precision     0.852796    0.773019     0.77451  0.804886\n",
      "======== Naive Bayes =======\n",
      "                pred_0      pred_1       pred_2    recall\n",
      "actual_0   1113.000000   24.000000   108.000000  0.893976\n",
      "actual_1    131.000000  323.000000   148.000000  0.536545\n",
      "actual_2    131.000000   42.000000  1091.000000  0.863133\n",
      "precision     0.809455    0.830334     0.809948  0.812279\n",
      "======== SVM =======\n",
      "                pred_0      pred_1       pred_2    recall\n",
      "actual_0   1070.000000   49.000000   126.000000  0.859438\n",
      "actual_1     83.000000  391.000000   128.000000  0.649502\n",
      "actual_2     90.000000   80.000000  1094.000000  0.865506\n",
      "precision     0.860821    0.751923     0.811573  0.821279\n",
      "======== Random Forest =======\n",
      "                pred_0      pred_1      pred_2    recall\n",
      "actual_0   1107.000000   53.000000   85.000000  0.889157\n",
      "actual_1    123.000000  350.000000  129.000000  0.581395\n",
      "actual_2    236.000000   95.000000  933.000000  0.738133\n",
      "precision     0.755116    0.702811    0.813426  0.768242\n"
     ]
    }
   ],
   "source": [
    "model = 'Installment'\n",
    "df = pd.read_csv('../../MLModel/data/{}/cleaned_mock_up_data.csv'.format(model))\n",
    "other_label = max(set(df.label))\n",
    "# filter out other label\n",
    "df = df[df.label != other_label]\n",
    "# get availabel other labels\n",
    "other_set = set(other_matrix[other_matrix[model]==0].label.values)\n",
    "ava_others = sub_df(others,other_set)\n",
    "ava_others[target] = other_label\n",
    "ava_others = ava_others.rename({'text':'split_text'},axis=1)\n",
    "df = pd.concat([df,ava_others],sort=True)\n",
    "# df = df.sample(frac=1,).reset_index(drop=True)\n",
    "print('=====  {} ======='.format(model))\n",
    "print(df.label.value_counts())\n",
    "print('begin training!')\n",
    "train,val = train_test_split(df,test_size=0.3,train_size=0.7,random_state=19)\n",
    "\n",
    "\n",
    "\n",
    "# get tfidf\n",
    "phrase_vectorizer = TfidfVectorizer(\n",
    "                                ngram_range=(1,3),\n",
    "                                strip_accents='unicode', \n",
    "                                max_features=100000, \n",
    "                                analyzer='word',\n",
    "                                sublinear_tf=True,\n",
    "                                use_idf=True,\n",
    "                                norm='l2',\n",
    "                                token_pattern=r'\\w{1,}')\n",
    "\n",
    "print('fitting phrase')\n",
    "phrase_vectorizer.fit(train.split_text)\n",
    "\n",
    "print('transform phrase')\n",
    "phrase_train = phrase_vectorizer.transform(train.split_text)\n",
    "phrase_val = phrase_vectorizer.transform(val.split_text)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "l_svc = LinearSVC(C=1)\n",
    "lsvc = CalibratedClassifierCV(l_svc) \n",
    "lsvc.fit(phrase_train, train.label)\n",
    "val_pred = lsvc.predict(phrase_val)\n",
    "evl = eval_mat(val.label.values, val_pred)\n",
    "print('======== Linear SVC =======')\n",
    "print(evl)\n",
    "\n",
    "\n",
    "# logistic\n",
    "log_r = LogisticRegression()\n",
    "log_r.fit(phrase_train, train.label)\n",
    "val_pred = log_r.predict(phrase_val)\n",
    "evl = eval_mat(val.label.values, val_pred)\n",
    "print('======== logistic =======')\n",
    "print(evl)\n",
    "\n",
    "\n",
    "# Naive Bayes\n",
    "naive_b = MultinomialNB()\n",
    "naive_b.fit(phrase_train, train.label)\n",
    "val_pred = naive_b.predict(phrase_val)\n",
    "evl = eval_mat(val.label.values, val_pred)\n",
    "print('======== Naive Bayes =======')\n",
    "print(evl)\n",
    "\n",
    "# SVM\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(phrase_train, train.label)\n",
    "val_pred = svm.predict(phrase_val)\n",
    "evl = eval_mat(val.label.values, val_pred)\n",
    "print('======== SVM =======')\n",
    "print(evl)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(phrase_train, train.label)\n",
    "val_pred = rf.predict(phrase_val)\n",
    "evl = eval_mat(val.label.values, val_pred)\n",
    "print('======== Random Forest =======')\n",
    "print(evl)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "======== Linear SVC =======\n",
    "                pred_0      pred_1      pred_2    recall\n",
    "actual_0   1092.000000   63.000000  104.000000  0.867355\n",
    "actual_1     57.000000  496.000000   79.000000  0.784810\n",
    "actual_2     88.000000   94.000000  648.000000  0.780723\n",
    "precision     0.882781    0.759571    0.779783  0.821757\n",
    "======== logistic =======\n",
    "                pred_0      pred_1      pred_2    recall\n",
    "actual_0   1093.000000   52.000000  114.000000  0.868149\n",
    "actual_1     85.000000  457.000000   90.000000  0.723101\n",
    "actual_2     95.000000   74.000000  661.000000  0.796386\n",
    "precision     0.858602    0.783877    0.764162  0.812569\n",
    "======== Naive Bayes =======\n",
    "                pred_0      pred_1   pred_2    recall\n",
    "actual_0   1163.000000   37.000000   59.000  0.923749\n",
    "actual_1    124.000000  441.000000   67.000  0.697785\n",
    "actual_2    180.000000   56.000000  594.000  0.715663\n",
    "precision     0.792774    0.825843    0.825  0.807791\n",
    "======== SVM =======\n",
    "                pred_0     pred_1      pred_2    recall\n",
    "actual_0   1093.000000   60.00000  106.000000  0.868149\n",
    "actual_1     62.000000  492.00000   78.000000  0.778481\n",
    "actual_2     93.000000   88.00000  649.000000  0.781928\n",
    "precision     0.875801    0.76875    0.779112  0.821022\n",
    "======== Random Forest =======\n",
    "                pred_0      pred_1      pred_2    recall\n",
    "actual_0   1148.000000   40.000000   71.000000  0.911835\n",
    "actual_1    108.000000  435.000000   89.000000  0.688291\n",
    "actual_2    192.000000   87.000000  551.000000  0.663855\n",
    "precision     0.792818    0.774021    0.774965  0.784270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# params={'task':'train','objective':'multiclass','num_class':3,}\n",
    "\n",
    "# train_set = lgb.Dataset(phrase_train,train.label.values)\n",
    "# model = lgb.train(params=params,train_set=train_set)\n",
    "# val_pred = model.predict(phrase_val)\n",
    "# val_pred = np.argmax(val_pred,axis=1)\n",
    "# evl = eval_mat(val.label.values, val_pred)\n",
    "# print('======== lightgbm =======')\n",
    "# print(evl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
