{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T03:34:42.080997Z",
     "start_time": "2018-07-19T03:34:42.073852Z"
    }
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "# import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "import sys,os\n",
    "sys.path.append('../../MLModel/code/OneClickTraining/')\n",
    "from all_model_py import CutDebt, IDClassifier, IfKnowDebtor, Installment, WillingToPay, ConfirmLoan\n",
    "\n",
    "sys.path.append('../../Lib/')\n",
    "from model_matrix import eval_mat\n",
    "from SUPPORT import balance_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T03:34:45.765192Z",
     "start_time": "2018-07-19T03:34:45.755607Z"
    }
   },
   "outputs": [],
   "source": [
    "def sub_df(df,sets,target='label'):\n",
    "    result = pd.DataFrame()\n",
    "    for each in sets:\n",
    "        result = pd.concat([result,df[df[target]==each]])\n",
    "#     print(result[target].value_counts())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T03:34:47.343366Z",
     "start_time": "2018-07-19T03:34:47.296748Z"
    }
   },
   "outputs": [],
   "source": [
    "others = pd.read_csv('../../MLModel/data/others/cleaned_mock_up_data.csv')\n",
    "other_matrix = pd.read_csv('../../MLModel/data/others/strategy_mat.csv')\n",
    "target = 'label'\n",
    "save_path = '../../MLModel/savedModel/{}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CutDebt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T03:38:55.184985Z",
     "start_time": "2018-07-19T03:38:55.176940Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_list = {'CutDebt':CutDebt,\n",
    "              'IDClassifier':IDClassifier,\n",
    "              'IfKnowDebtor':IfKnowDebtor,\n",
    "              'Installment':Installment,\n",
    "              'ConfirmLoan':ConfirmLoan,\n",
    "              'WillingToPay':WillingToPay}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T03:41:31.918700Z",
     "start_time": "2018-07-19T03:41:24.226591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====  ConfirmLoan =======\n",
      "2    4280\n",
      "0    4278\n",
      "1    3836\n",
      "Name: label, dtype: int64\n",
      "begin training!\n",
      "fitting phrase\n",
      "transform phrase\n",
      "======== Linear SVC =======\n",
      "                pred_0      pred_1       pred_2    recall\n",
      "actual_0   1258.000000     0.00000     5.000000  0.996041\n",
      "actual_1      0.000000  1129.00000     8.000000  0.992964\n",
      "actual_2     38.000000    39.00000  1242.000000  0.941622\n",
      "precision     0.970679     0.96661     0.989641  0.975800\n",
      "======== logistic =======\n",
      "                pred_0      pred_1       pred_2    recall\n",
      "actual_0   1241.000000     4.00000    18.000000  0.982581\n",
      "actual_1      0.000000  1117.00000    20.000000  0.982410\n",
      "actual_2     72.000000    55.00000  1192.000000  0.903715\n",
      "precision     0.945164     0.94983     0.969106  0.954558\n",
      "======== Naive Bayes =======\n",
      "                pred_0       pred_1       pred_2    recall\n",
      "actual_0   1240.000000    17.000000     6.000000  0.981789\n",
      "actual_1      0.000000  1124.000000    13.000000  0.988566\n",
      "actual_2    105.000000   103.000000  1111.000000  0.842305\n",
      "precision     0.921933     0.903537     0.983186  0.934391\n",
      "======== SVM =======\n",
      "                pred_0       pred_1       pred_2    recall\n",
      "actual_0   1258.000000     0.000000     5.000000  0.996041\n",
      "actual_1      0.000000  1134.000000     3.000000  0.997361\n",
      "actual_2     37.000000    47.000000  1235.000000  0.936315\n",
      "precision     0.971429     0.960203     0.993564  0.975262\n",
      "======== Random Forest =======\n",
      "                pred_0       pred_1       pred_2    recall\n",
      "actual_0   1260.000000     0.000000     3.000000  0.997625\n",
      "actual_1      0.000000  1132.000000     5.000000  0.995602\n",
      "actual_2     39.000000    26.000000  1254.000000  0.950720\n",
      "precision     0.969977     0.977547     0.993661  0.980371\n"
     ]
    }
   ],
   "source": [
    "model = 'ConfirmLoan'\n",
    "df = pd.read_csv('../../MLModel/data/{}/cleaned_mock_up_data.csv'.format(model))\n",
    "other_label = int(max(set(df.label)) + 1)\n",
    "# filter out other label\n",
    "\n",
    "# get availabel other labels\n",
    "other_set = set(other_matrix[other_matrix[model]==0].label.values)\n",
    "ava_others = sub_df(others,other_set)\n",
    "ava_others[target] = other_label\n",
    "ava_others = ava_others.rename({'text':'split_text'},axis=1)\n",
    "df = pd.concat([df,ava_others],sort=True)\n",
    "df = balance_category(df,target='label')\n",
    "df = df.sample(frac=1,random_state=21).reset_index(drop=True)\n",
    "\n",
    "print('=====  {} ======='.format(model))\n",
    "print(df.label.value_counts())\n",
    "print('begin training!')\n",
    "train,val = train_test_split(df,test_size=0.3,train_size=0.7,random_state=19)\n",
    "\n",
    "\n",
    "\n",
    "# get tfidf\n",
    "phrase_vectorizer = TfidfVectorizer(\n",
    "                                ngram_range=(1,3),\n",
    "                                strip_accents='unicode', \n",
    "                                max_features=100000, \n",
    "                                analyzer='word',\n",
    "                                sublinear_tf=True,\n",
    "                                use_idf=True,\n",
    "                                norm='l2',\n",
    "                                token_pattern=r'\\w{1,}')\n",
    "\n",
    "print('fitting phrase')\n",
    "phrase_vectorizer.fit(train.split_text)\n",
    "\n",
    "print('transform phrase')\n",
    "phrase_train = phrase_vectorizer.transform(train.split_text)\n",
    "phrase_val = phrase_vectorizer.transform(val.split_text)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "l_svc = LinearSVC(C=1)\n",
    "lsvc = CalibratedClassifierCV(l_svc) \n",
    "lsvc.fit(phrase_train, train.label)\n",
    "val_pred = lsvc.predict(phrase_val)\n",
    "evl = eval_mat(val.label.values, val_pred)\n",
    "print('======== Linear SVC =======')\n",
    "print(evl)\n",
    "\n",
    "\n",
    "# logistic\n",
    "log_r = LogisticRegression()\n",
    "log_r.fit(phrase_train, train.label)\n",
    "val_pred = log_r.predict(phrase_val)\n",
    "evl = eval_mat(val.label.values, val_pred)\n",
    "print('======== logistic =======')\n",
    "print(evl)\n",
    "\n",
    "\n",
    "# Naive Bayes\n",
    "naive_b = MultinomialNB()\n",
    "naive_b.fit(phrase_train, train.label)\n",
    "val_pred = naive_b.predict(phrase_val)\n",
    "evl = eval_mat(val.label.values, val_pred)\n",
    "print('======== Naive Bayes =======')\n",
    "print(evl)\n",
    "\n",
    "# SVM\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(phrase_train, train.label)\n",
    "val_pred = svm.predict(phrase_val)\n",
    "evl = eval_mat(val.label.values, val_pred)\n",
    "print('======== SVM =======')\n",
    "print(evl)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(phrase_train, train.label)\n",
    "val_pred = rf.predict(phrase_val)\n",
    "evl = eval_mat(val.label.values, val_pred)\n",
    "print('======== Random Forest =======')\n",
    "print(evl)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "======== Linear SVC =======\n",
    "               pred_0      pred_1      pred_2    recall\n",
    "actual_0   192.000000   10.000000    11.00000  0.901408\n",
    "actual_1     6.000000  116.000000    26.00000  0.783784\n",
    "actual_2    49.000000   22.000000  1231.00000  0.945469\n",
    "precision    0.777328    0.783784     0.97082  0.925436\n",
    "======== logistic =======\n",
    "               pred_0     pred_1      pred_2    recall\n",
    "actual_0   141.000000   8.000000    64.00000  0.661972\n",
    "actual_1     6.000000  69.000000    73.00000  0.466216\n",
    "actual_2    16.000000   8.000000  1278.00000  0.981567\n",
    "precision    0.865031   0.811765     0.90318  0.894768\n",
    "======== Naive Bayes =======\n",
    "           pred_0  pred_1       pred_2    recall\n",
    "actual_0     78.0    2.00   133.000000  0.366197\n",
    "actual_1      0.0   47.00   101.000000  0.317568\n",
    "actual_2      0.0    1.00  1301.000000  0.999232\n",
    "precision     1.0    0.94     0.847557  0.857486\n",
    "======== SVM =======\n",
    "               pred_0      pred_1       pred_2    recall\n",
    "actual_0   185.000000    9.000000    19.000000  0.868545\n",
    "actual_1     5.000000  107.000000    36.000000  0.722973\n",
    "actual_2    41.000000   15.000000  1246.000000  0.956989\n",
    "precision    0.800866    0.816794     0.957725  0.924835\n",
    "======== Random Forest =======\n",
    "           pred_0     pred_1       pred_2    recall\n",
    "actual_0   162.00   6.000000    45.000000  0.760563\n",
    "actual_1     9.00  93.000000    46.000000  0.628378\n",
    "actual_2    29.00  12.000000  1261.000000  0.968510\n",
    "precision    0.81   0.837838     0.932692  0.911606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# params={'task':'train','objective':'multiclass','num_class':3,}\n",
    "\n",
    "# train_set = lgb.Dataset(phrase_train,train.label.values)\n",
    "# model = lgb.train(params=params,train_set=train_set)\n",
    "# val_pred = model.predict(phrase_val)\n",
    "# val_pred = np.argmax(val_pred,axis=1)\n",
    "# evl = eval_mat(val.label.values, val_pred)\n",
    "# print('======== lightgbm =======')\n",
    "# print(evl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:01:52.059708Z",
     "start_time": "2018-07-19T04:01:52.051937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6006"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('6006')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
