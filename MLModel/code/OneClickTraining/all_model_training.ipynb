{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T17:57:43.068779Z",
     "start_time": "2018-07-02T17:57:43.060488Z"
    }
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import pickle\n",
    "\n",
    "from all_model_py import CutDebt, IDClassifier, IfKnowDebtor, Installment, WillingToPay, ConfirmLoan\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('../CutDebt/')\n",
    "# sys.path.append('../IDClassifier/')\n",
    "# sys.path.append('../IfKnowDebtor/')\n",
    "# sys.path.append('../Installment/')\n",
    "# sys.path.append('../SetDueDay/')\n",
    "# sys.path.append('../WillingToPay/')\n",
    "\n",
    "# from CutDebt_py import CutDebt\n",
    "# from IDClassifier_py import IDClassifier\n",
    "# from IfKnowDebtor_py import IfKnowDebtor\n",
    "# from Installment_py import Installment\n",
    "# from SetDueDay_py import SetDueDay\n",
    "# from WillingToPay_py import WillingToPay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T17:57:48.120744Z",
     "start_time": "2018-07-02T17:57:44.155003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutDebt\n",
      "0    4073\n",
      "2    2180\n",
      "1    2088\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "IDClassifier\n",
      "0    1427\n",
      "2    1293\n",
      "1    1272\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "IfKnowDebtor\n",
      "0    1461\n",
      "2    1295\n",
      "1    1156\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "Installment\n",
      "0    4073\n",
      "2    2180\n",
      "1    2088\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "ConfirmLoan\n",
      "2    283\n",
      "1    212\n",
      "0    201\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "WillingToPay\n",
      "0    2089\n",
      "2    2053\n",
      "1    2042\n",
      "3    1273\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n"
     ]
    }
   ],
   "source": [
    "model_list = ['CutDebt','IDClassifier','IfKnowDebtor','Installment','ConfirmLoan','WillingToPay']\n",
    "func_list = [CutDebt,IDClassifier,IfKnowDebtor,Installment,ConfirmLoan,WillingToPay]\n",
    "\n",
    "ind = 0\n",
    "for each_model in model_list:\n",
    "    print(each_model)\n",
    "    \n",
    "    # load data\n",
    "    path = '../../data/{}/'\n",
    "    data_train = pd.read_csv(path.format(each_model) + 'cleaned_mock_up_data.csv', encoding='utf8')\n",
    "    print(data_train.label.value_counts())\n",
    "\n",
    "    \n",
    "    # get tfidf\n",
    "    phrase_vectorizer = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                    strip_accents='unicode', \n",
    "                                    max_features=100000, \n",
    "                                    analyzer='word',\n",
    "                                    sublinear_tf=True,\n",
    "                                    token_pattern=r'\\w{1,}')\n",
    "\n",
    "    print('fitting phrase')\n",
    "    phrase_vectorizer.fit(data_train.split_text)\n",
    "\n",
    "    print('transform phrase')\n",
    "    phrase = phrase_vectorizer.transform(data_train.split_text)\n",
    "\n",
    "    \n",
    "    # linear svc\n",
    "    l_svc = LinearSVC()\n",
    "    lsvc = CalibratedClassifierCV(l_svc) \n",
    "    lsvc.fit(phrase, data_train.label)\n",
    "    \n",
    "    \n",
    "    # logistic\n",
    "    log_r = LogisticRegression()\n",
    "    log_r.fit(phrase, data_train.label)\n",
    "    \n",
    "    \n",
    "    # Naive Bayes\n",
    "    naive_b = MultinomialNB()\n",
    "    naive_b.fit(phrase, data_train.label)\n",
    "    \n",
    "    \n",
    "    print('finish training')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     for threhold\n",
    "    \n",
    "    # save model\n",
    "    save_path = '../../savedModel/{}/'\n",
    "#     # save tfidf\n",
    "#     pickle.dump(phrase_vectorizer, open(save_path.format(each_model) + \"tfidf.pickle\", \"wb\"))\n",
    "#     # save linear svc\n",
    "#     pickle.dump(lsvc, open(save_path.format(each_model) + \"LinearSVC.pickle\", \"wb\"))\n",
    "#     # save logistic\n",
    "#     pickle.dump(log_r, open(save_path.format(each_model) + \"Logistic.pickle\", \"wb\"))\n",
    "#     # save lightGBM\n",
    "# #     pickle.dump(lgbm_model, open(save_path.format(each_model) + \"Lgbm.pickle\", \"wb\"))\n",
    "#     # save naive bayes\n",
    "#     pickle.dump(naive_b, open(save_path.format(each_model) + \"nb.pickle\", \"wb\"))\n",
    "\n",
    "    \n",
    "    other = pickle.load(open('../../savedModel/others/{}/{}_other.pickle'.format(each_model,each_model),'rb'))\n",
    "    \n",
    "    func = func_list[ind]\n",
    "    result = func(svc=lsvc, logistic=log_r, nb=naive_b, tfidf=phrase_vectorizer, other=other,  jieba_path='../WordCut/userdict.txt')\n",
    "    pickle.dump(result, open(save_path.format(each_model) + each_model + '.pickle', \"wb\"))\n",
    "    ind = ind + 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T17:57:48.209732Z",
     "start_time": "2018-07-02T17:57:48.200810Z"
    }
   },
   "outputs": [],
   "source": [
    "# import jieba\n",
    "# sentence = '好'\n",
    "# sentence = jieba.cut(sentence)\n",
    "# sentence = ' '.join(sentence)\n",
    "# sentence = phrase_vectorizer.transform([sentence])\n",
    "# naive_b.predict_proba(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T17:57:48.555282Z",
     "start_time": "2018-07-02T17:57:48.274365Z"
    }
   },
   "outputs": [],
   "source": [
    "idc = pickle.load(open(\"../../savedModel/IDClassifier/IDClassifier.pickle\", 'rb'))\n",
    "cutd = pickle.load(open(\"../../savedModel/CutDebt/CutDebt.pickle\", 'rb'))\n",
    "ifk = pickle.load(open(\"../../savedModel/IfKnowDebtor/IfKnowDebtor.pickle\", 'rb'))\n",
    "will = pickle.load(open(\"../../savedModel/WillingToPay/WillingToPay.pickle\", 'rb'))\n",
    "inst = pickle.load(open(\"../../savedModel/Installment/Installment.pickle\", 'rb'))\n",
    "conf = pickle.load(open(\"../../savedModel/ConfirmLoan/ConfirmLoan.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T17:43:23.223564Z",
     "start_time": "2018-07-02T17:43:23.204831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'pred_prob': array([[0.82187333, 0.09306548, 0.05836066, 0.02670052],\n",
       "        [0.79447589, 0.1035233 , 0.07310615, 0.02889466],\n",
       "        [0.7043463 , 0.12667717, 0.13270743, 0.03626911]]),\n",
       " 'av_pred': array([0.77356517, 0.10775532, 0.08805808, 0.03062143]),\n",
       " 'time_extract': [{'pattern': '星期三',\n",
       "   'time': datetime.datetime(2018, 7, 4, 19, 0, tzinfo=<DstTzInfo 'America/New_York' EDT-1 day, 20:00:00 DST>),\n",
       "   'gapS': 177396.793736,\n",
       "   'gapH': 49.27688714888889}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "will.classify('我星期三就还',lower_bounder=36,upper_bounder=24*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
