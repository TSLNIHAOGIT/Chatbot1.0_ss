{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T01:35:54.864227Z",
     "start_time": "2018-08-20T01:35:54.168030Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "import sys,os\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T03:17:19.183450Z",
     "start_time": "2018-08-20T03:17:19.116330Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "import sys,os\n",
    "tpattern_path = '../../../classifier/models/time_pattern/'\n",
    "sys.path.append(tpattern_path)\n",
    "from time_pattern import TimePattern\n",
    "env_path = '../../../classifier/env/'\n",
    "sys.path.append(env_path)\n",
    "from env import ENV\n",
    "log_path = '../../../classifier/lib/'\n",
    "sys.path.append(log_path)\n",
    "from log import Logger\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BaseClassifier:\n",
    "    def __init__(self, **model):\n",
    "        \"\"\"\n",
    "        suggested parameters:\n",
    "        svc, logistic, nb, jieba_path,tfidf\n",
    "        \"\"\"\n",
    "        self._load_model(**model)\n",
    "        self.log = None\n",
    "        \n",
    "    def warm_up(self):\n",
    "        self.other.classify('')\n",
    "        \n",
    "    def _load_model(self,**model):\n",
    "        self.svc = model.get('svc')\n",
    "        self.logistic = model.get('logistic')\n",
    "        self.nb = model.get('nb')\n",
    "        self.tfidf = model.get('tfidf')\n",
    "        self.other = model.get('other')\n",
    "        # load jieba\n",
    "        jieba_path = model.get('jieba_path')\n",
    "        if jieba_path is not None:\n",
    "            jieba.load_userdict(jieba_path)\n",
    "            \n",
    "    def _ext_time(self,sentence, lower_bounder=36, upper_bounder=24*15):\n",
    "        \"\"\"\n",
    "        time label 0: extract length is 0\n",
    "        time label 2: extract length is 2\n",
    "        time label 10: extract length is 1, delta time is within the shortest time\n",
    "        time label 11: extract length is 1, delta time is within the middle time\n",
    "        time label 12: extract length is 1, delta time is greater than the longest time\n",
    "        \"\"\"\n",
    "        time_extract = self.re_time.process(sentence)\n",
    "        time_label = 0\n",
    "        if len(time_extract) == 0:\n",
    "            time_label = 0\n",
    "            self.log.debug('No time was extracted!')\n",
    "        elif len(time_extract) > 1:\n",
    "            time_label = 2\n",
    "            self.log.debug('More than 2 times were extracted!')\n",
    "        else:\n",
    "            delta = time_extract[0]['gapH']\n",
    "            self.log.debug('Just one time was extracted! And the time delta is {} hours'.format(delta))\n",
    "            if delta < lower_bounder:\n",
    "                time_label = 10\n",
    "                self.log.debug('The delta is less than lower bounder {} hours'.format(lower_bounder))\n",
    "            elif lower_bounder <= delta < upper_bounder:\n",
    "                time_label = 11\n",
    "                self.log.debug('The delta is greater than lower bounder {} hours but less than upper bounder {} hours'.format(lower_bounder,upper_bounder))\n",
    "            else:\n",
    "                time_label = 12\n",
    "                self.log.debug('The delta is greater than upper bounder {} hours'.format(upper_bounder))\n",
    "                \n",
    "        return {'label':time_label,'time_extract':time_extract}\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "class IDClassifier(BaseClassifier):\n",
    "    \n",
    "    def __init__(self,**model):\n",
    "        super().__init__(**model)\n",
    "        self.label_meaning = 'ifDebtorAnswersing'\n",
    "        self.label_meaning_map = {0:'y',1:'n'}\n",
    "       \n",
    "    def classify(self, sentence,lower_bounder=None,upper_bounder=None,debug=False):\n",
    "        \"\"\"\n",
    "        ML model wrapper. No time regular expression involved!\n",
    "        input: sentence - type string\n",
    "        return label\n",
    "        \"\"\"\n",
    "        if self.log is None:\n",
    "            self.log = Logger(self.__class__.__name__,level=ENV.MODEL_LOG_LEVEL.value).logger\n",
    "        sentence = jieba.cut(sentence, cut_all = False)\n",
    "        sentence = ' '.join(sentence)\n",
    "        matrix = self.tfidf.transform([sentence])\n",
    "        self.log.debug('In transfered tfidf, the number of words in vocalbulary is: {}'.format(len(matrix.data)))\n",
    "        result = np.vstack((self.svc.predict_proba(matrix),\n",
    "                                 self.logistic.predict_proba(matrix),\n",
    "                                 self.nb.predict_proba(matrix)))\n",
    "        \n",
    "        av_pred = np.mean(result, axis = 0)\n",
    "        max_pred = np.max(av_pred, axis = 0)\n",
    "        max_arg = np.argmax(av_pred)\n",
    "        response = None\n",
    "        label = max_arg\n",
    "        if label == 2:\n",
    "            response = self.other.classify(sentence)\n",
    "            label = response['label']\n",
    "        if debug:\n",
    "            dictionary = {'label': label, 'pred_prob': result, 'av_pred': av_pred,'other_response':response}\n",
    "        else:\n",
    "            if response is not None:\n",
    "                response = float(max(response['av_pred']))\n",
    "            av_pred_value = float(max(av_pred))\n",
    "            dictionary = {'label': label, 'av_pred': av_pred_value,'other_response':response}\n",
    "        self.log.debug('Final Pred label is: {}'.format(label))\n",
    "        dictionary.update({self.label_meaning:self.label_meaning_map.get(label,'null')})\n",
    "        return dictionary\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class IfKnowDebtor(BaseClassifier):\n",
    "    \n",
    "    def __init__(self,**model):\n",
    "        super().__init__(**model)\n",
    "        self.label_meaning = 'ifKnowDebtor'\n",
    "        self.label_meaning_map = {0:'y',1:'n'}\n",
    "        \n",
    "        \n",
    "    def classify(self, sentence,lower_bounder=None,upper_bounder=None,debug=False):\n",
    "        \"\"\"\n",
    "        ML model wrapper. No time regular expression involved!\n",
    "        input: sentence - type string\n",
    "        return label\n",
    "        \"\"\"\n",
    "        if self.log is None:\n",
    "            self.log = Logger(self.__class__.__name__,level=ENV.MODEL_LOG_LEVEL.value).logger\n",
    "        sentence = jieba.cut(sentence, cut_all = False)\n",
    "        sentence = ' '.join(sentence)\n",
    "        matrix = self.tfidf.transform([sentence])\n",
    "        self.log.debug('In transfered tfidf, the number of words in vocalbulary is: {}'.format(len(matrix.data)))\n",
    "        result = np.vstack((self.svc.predict_proba(matrix),\n",
    "                                 self.logistic.predict_proba(matrix),\n",
    "                                 self.nb.predict_proba(matrix)))\n",
    "        \n",
    "        av_pred = np.mean(result, axis = 0)\n",
    "        max_pred = np.max(av_pred, axis = 0)\n",
    "        max_arg = np.argmax(av_pred)\n",
    "        response = None\n",
    "        label = max_arg\n",
    "        if label == 2:\n",
    "            response = self.other.classify(sentence)\n",
    "            label = response['label']\n",
    "        if debug:\n",
    "            dictionary = {'label': label, 'pred_prob': result, 'av_pred': av_pred,'other_response':response}\n",
    "        else:\n",
    "            if response is not None:\n",
    "                response = float(max(response['av_pred']))\n",
    "            av_pred_value = float(max(av_pred))\n",
    "            dictionary = {'label': label, 'av_pred': av_pred_value,'other_response':response}\n",
    "        \n",
    "        self.log.debug('Final Pred label is: {}'.format(label))\n",
    "        dictionary.update({self.label_meaning:self.label_meaning_map.get(label,'null')})\n",
    "        return dictionary\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "class ConfirmLoan(BaseClassifier):\n",
    "    \n",
    "    def __init__(self,**model):\n",
    "        super().__init__(**model)\n",
    "        self.re_time = TimePattern()\n",
    "        self.label_meaning = 'ifAdmitLoan'\n",
    "        self.label_meaning_map = {0:'y',1:'n'}\n",
    "        \n",
    "    def classify(self, sentence,lower_bounder=36, upper_bounder=72,debug=False):\n",
    "        \"\"\"\n",
    "        if len(time_extract) == 0 --> run through ML\n",
    "        if len(time_extract) == 1(within short time) --> jump to n103\n",
    "            other --> jump to n15\n",
    "        \"\"\"\n",
    "        if self.log is None:\n",
    "            self.log = Logger(self.__class__.__name__,level=ENV.MODEL_LOG_LEVEL.value).logger\n",
    "        time_result = self._ext_time(sentence,lower_bounder, upper_bounder)\n",
    "        time_label = time_result['label']\n",
    "        time_extract = time_result['time_extract']\n",
    "        # remove time pattern from setence\n",
    "        sentence = self.re_time.remove_time(sentence)\n",
    "        sentence = jieba.cut(sentence, cut_all = False)\n",
    "        sentence = ' '.join(sentence)\n",
    "        matrix = self.tfidf.transform([sentence])\n",
    "        self.log.debug('In transfered tfidf, the number of words in vocalbulary is: {}'.format(len(matrix.data)))\n",
    "        result = np.vstack((self.svc.predict_proba(matrix),\n",
    "                                 self.logistic.predict_proba(matrix),\n",
    "                                 self.nb.predict_proba(matrix)))\n",
    "        \n",
    "        av_pred = np.mean(result, axis = 0)\n",
    "        max_pred = np.max(av_pred, axis = 0)\n",
    "        max_arg = np.argmax(av_pred)\n",
    "        response = None\n",
    "        label = max_arg\n",
    "        if label == 2:\n",
    "            response = self.other.classify(sentence)\n",
    "            label = response['label']\n",
    "        \n",
    "        # interact with regular expression\n",
    "        if (time_label == 10) and (label != 1):\n",
    "            label = 10\n",
    "    \n",
    "        if debug:\n",
    "            dictionary = {'label': label, 'pred_prob': result, 'av_pred': av_pred,'other_response':response}\n",
    "        else:\n",
    "            if response is not None:\n",
    "                response = float(max(response['av_pred']))\n",
    "            av_pred_value = float(max(av_pred))\n",
    "            dictionary = {'label': label, 'av_pred': av_pred_value,'other_response':response}\n",
    "        dictionary.update({'timeExtract':time_extract})\n",
    "        self.log.debug('Final Pred label is: {}'.format(label))\n",
    "        dictionary.update({self.label_meaning:self.label_meaning_map.get(label,'null')})\n",
    "        return dictionary\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "class WillingToPay(BaseClassifier):\n",
    "    def __init__(self,**model):\n",
    "        super().__init__(**model)\n",
    "        self.re_time = TimePattern()\n",
    "        self.label_meaning = 'ifWillingToPay'\n",
    "        self.label_meaning_map = {0:'y',1:'n'}\n",
    "    \n",
    "        \n",
    "        \n",
    "    def classify(self, sentence, lower_bounder=36, upper_bounder=72,debug=False):\n",
    "        \"\"\"\n",
    "        0 - high willing to pay (ML + Reg, between short and long)\n",
    "        1 - not willing to pay (ML + Reg, too long)\n",
    "        2 - hope to cut\n",
    "        3 - other\n",
    "        Re:\n",
    "        if time len(extract) >=2, and the min time is within the tolerance --> connect to self and confirm which day to pay,\n",
    "                                    output label is 10\n",
    "        if time len(extract) ==1, and the min time is within the tolerance --> run through ML\n",
    "                                    and the min time is within the middle time --> not run ML, connect to self, output label 1,\n",
    "                                    and the min time is longer than the longest time --> no ML, connect to self,output1 sentiment +1\n",
    "        \"\"\"\n",
    "        if self.log is None:\n",
    "            self.log = Logger(self.__class__.__name__,level=ENV.MODEL_LOG_LEVEL.value).logger\n",
    "        dictionary = {}\n",
    "        # Regular expression\n",
    "        time_result = self._ext_time(sentence,lower_bounder, upper_bounder)\n",
    "        time_label = time_result['label']\n",
    "        time_extract = time_result['time_extract']\n",
    "        response = None\n",
    "        if time_label == 2:\n",
    "            min_time = time_extract[0]['gapH']\n",
    "            for each in time_extract[1:]:\n",
    "                _time = each['gapH']\n",
    "                if _time < min_time:\n",
    "                    min_time = _time\n",
    "            if min_time <= lower_bounder:\n",
    "                self.log.debug('There are more than 1 time extracted. And the min {} hours is shorter than lower bounder! The output label is set to 10!'.format(min_time))\n",
    "                return {'label':10 , 'pred_prob': 1.0, 'av_pred': 1.0, 'time_extract':time_extract}\n",
    "        else:           \n",
    "            # ML model process\n",
    "            # remove time pattern from setence\n",
    "            sentence = self.re_time.remove_time(sentence)\n",
    "            sentence = jieba.cut(sentence, cut_all = False)\n",
    "            sentence = ' '.join(sentence)\n",
    "            matrix = self.tfidf.transform([sentence])\n",
    "            self.log.debug('In transfered tfidf, the number of words in vocalbulary is: {}'.format(len(matrix.data)))\n",
    "            result = np.vstack((self.svc.predict_proba(matrix),\n",
    "                                     self.logistic.predict_proba(matrix),\n",
    "                                     self.nb.predict_proba(matrix)))\n",
    "\n",
    "            av_pred = np.mean(result, axis = 0)\n",
    "            max_pred = np.max(av_pred, axis = 0)\n",
    "            max_arg = np.argmax(av_pred)\n",
    "            label = max_arg\n",
    "            \n",
    "\n",
    "            if label == 3:\n",
    "                response = self.other.classify(sentence)\n",
    "                label = response['label']\n",
    "            # interact with regular expression\n",
    "            if (time_label == 2) and (label != 1):\n",
    "                label = 10\n",
    "            \n",
    "            ####### interact with Regular expression\n",
    "            if time_label == 11:\n",
    "                label = 1\n",
    "            elif time_label == 12:\n",
    "                label = 1\n",
    "                dictionary.update({'add_sentiment':1})\n",
    "            if debug:\n",
    "                dictionary = {'label': label, 'pred_prob': result, 'av_pred': av_pred,'other_response':response}\n",
    "            else:\n",
    "                if response is not None:\n",
    "                    response = float(max(response['av_pred']))\n",
    "                av_pred_value = float(max(av_pred))\n",
    "                dictionary = {'label': label, 'av_pred': av_pred_value,'other_response':response}\n",
    "            dictionary.update({'timeExtract':time_extract})\n",
    "            self.log.debug('Final Pred label is: {}'.format(label))\n",
    "            dictionary.update({self.label_meaning:self.label_meaning_map.get(label,'null')})\n",
    "            return dictionary\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class CutDebt(BaseClassifier):\n",
    "    def __init__(self,**model):\n",
    "        super().__init__(**model)\n",
    "        self.re_time = TimePattern()\n",
    "        self.label_meaning = 'ifAcceptCutDebt'\n",
    "        self.label_meaning_map = {0:'y',1:'n'}\n",
    "        \n",
    "    def classify(self, sentence,lower_bounder=36, upper_bounder=72,debug=False):\n",
    "        \"\"\"\n",
    "        Re:\n",
    "        if time len(extract) >=2, and the min time is within the tolerance --> connect to self and confirm which day to pay,\n",
    "                                    output label is 10\n",
    "        if time len(extract) ==1, and the min time is within the tolerance --> run through ML\n",
    "                                    and the min time is within the middle time --> not run ML, connect to self, output label 1,\n",
    "                                    and the min time is longer than the longest time --> no ML, connect to self,output1 sentiment +1\n",
    "        \"\"\"\n",
    "        if self.log is None:\n",
    "            self.log = Logger(self.__class__.__name__,level=ENV.MODEL_LOG_LEVEL.value).logger\n",
    "        dictionary = {}\n",
    "        # Regular expression\n",
    "        time_result = self._ext_time(sentence,lower_bounder, upper_bounder)\n",
    "        time_label = time_result['label']\n",
    "        time_extract = time_result['time_extract'] \n",
    "        response = None\n",
    "        if time_label == 2:\n",
    "            min_time = time_extract[0]['gapH']\n",
    "            for each in time_extract[1:]:\n",
    "                _time = each['gapH']\n",
    "                if _time < min_time:\n",
    "                    min_time = _time\n",
    "            if min_time <= lower_bounder:\n",
    "                self.log.debug('There are more than 1 time extracted. And the min {} hours is shorter than lower bounder! The output label is set to 10!'.format(min_time))\n",
    "                return {'label':10 , 'pred_prob': 1.0, 'av_pred': 1.0, 'time_extract':time_extract}\n",
    "        else:\n",
    "            # remove time pattern from setence\n",
    "            sentence = self.re_time.remove_time(sentence)\n",
    "            sentence = jieba.cut(sentence, cut_all = False)\n",
    "            sentence = ' '.join(sentence)\n",
    "            matrix = self.tfidf.transform([sentence])\n",
    "            self.log.debug('In transfered tfidf, the number of words in vocalbulary is: {}'.format(len(matrix.data)))\n",
    "            result = np.vstack((self.svc.predict_proba(matrix),\n",
    "                                     self.logistic.predict_proba(matrix),\n",
    "                                     self.nb.predict_proba(matrix)))\n",
    "\n",
    "            av_pred = np.mean(result, axis = 0)\n",
    "            max_pred = np.max(av_pred, axis = 0)\n",
    "            max_arg = np.argmax(av_pred)\n",
    "            label = max_arg\n",
    "            if label == 2:\n",
    "                response = self.other.classify(sentence)\n",
    "                label = response['label']\n",
    "\n",
    "            dictionary = {'label': label, 'pred_prob': result, 'av_pred': av_pred}\n",
    "            # interact with regular expression\n",
    "            if (time_label == 2) and (label != 1):\n",
    "                label = 10\n",
    "            \n",
    "            ####### interact with Regular expression\n",
    "            if time_label == 11:\n",
    "                label = 1\n",
    "            elif time_label == 12:\n",
    "                label = 1\n",
    "                dictionary.update({'add_sentiment':1})\n",
    "            if debug:\n",
    "                dictionary = {'label': label, 'pred_prob': result, 'av_pred': av_pred,'other_response':response}\n",
    "            else:\n",
    "                if response is not None:\n",
    "                    response = float(max(response['av_pred']))\n",
    "                av_pred_value = float(max(av_pred))\n",
    "                dictionary = {'label': label, 'av_pred': av_pred_value,'other_response':response}\n",
    "            dictionary.update({'timeExtract':time_extract})\n",
    "            self.log.debug('Final Pred label is: {}'.format(label))\n",
    "            dictionary.update({self.label_meaning:self.label_meaning_map.get(label,'null')})\n",
    "            return dictionary\n",
    "    \n",
    "    \n",
    "    \n",
    "class Installment(BaseClassifier):\n",
    "    def __init__(self,**model):\n",
    "        super().__init__(**model)\n",
    "        self.re_time = TimePattern()\n",
    "        self.label_meaning = 'ifAcceptInstallment'\n",
    "        self.label_meaning_map = {0:'y',1:'n'}\n",
    "        \n",
    "        \n",
    "    def classify(self, sentence,lower_bounder=36, upper_bounder=72,debug=False):\n",
    "        \"\"\"\n",
    "        Re:\n",
    "        if time len(extract) >=2, and the min time is within the tolerance --> connect to self and confirm which day to pay,\n",
    "                                    output label is 10\n",
    "        if time len(extract) ==1, and the min time is within the tolerance --> run through ML\n",
    "                                    and the min time is within the middle time --> not run ML, connect to self, output label 1,\n",
    "                                    and the min time is longer than the longest time --> no ML, connect to self,output1 sentiment +1\n",
    "        \"\"\"\n",
    "        if self.log is None:\n",
    "            self.log = Logger(self.__class__.__name__,level=ENV.MODEL_LOG_LEVEL.value).logger\n",
    "        dictionary= {}\n",
    "        # Regular expression\n",
    "        time_result = self._ext_time(sentence,lower_bounder, upper_bounder)\n",
    "        time_label = time_result['label']\n",
    "        time_extract = time_result['time_extract']    \n",
    "        response = None\n",
    "        if time_label == 2:\n",
    "            min_time = time_extract[0]['gapH']\n",
    "            for each in time_extract[1:]:\n",
    "                _time = each['gapH']\n",
    "                if _time < min_time:\n",
    "                    min_time = _time\n",
    "            if min_time <= lower_bounder:\n",
    "                self.log.debug('There are more than 1 time extracted. And the min {} hours is shorter than lower bounder! The output label is set to 10!'.format(min_time))\n",
    "                return {'label':10 , 'pred_prob': 1.0, 'av_pred': 1.0, 'time_extract':time_extract}\n",
    "        else:\n",
    "            # remove time pattern from setence\n",
    "            sentence = self.re_time.remove_time(sentence)\n",
    "            sentence = jieba.cut(sentence, cut_all = False)\n",
    "            sentence = ' '.join(sentence)\n",
    "            matrix = self.tfidf.transform([sentence])\n",
    "            self.log.debug('In transfered tfidf, the number of words in vocalbulary is: {}'.format(len(matrix.data)))\n",
    "            result = np.vstack((self.svc.predict_proba(matrix),\n",
    "                                     self.logistic.predict_proba(matrix),\n",
    "                                     self.nb.predict_proba(matrix)))\n",
    "\n",
    "            av_pred = np.mean(result, axis = 0)\n",
    "            max_pred = np.max(av_pred, axis = 0)\n",
    "            max_arg = np.argmax(av_pred)\n",
    "            label = max_arg\n",
    "\n",
    "            if label == 2:\n",
    "                response = self.other.classify(sentence)\n",
    "                label = response['label']\n",
    "\n",
    "            dictionary = {'label': label, 'pred_prob': result, 'av_pred': av_pred}\n",
    "            ####### interact with Regular expression\n",
    "            if time_label == 11:\n",
    "                label = 1\n",
    "            elif time_label == 12:\n",
    "                label = 1\n",
    "                dictionary.update({'add_sentiment':1})\n",
    "            if debug:\n",
    "                dictionary = {'label': label, 'pred_prob': result, 'av_pred': av_pred,'other_response':response}\n",
    "            else:\n",
    "                if response is not None:\n",
    "                    response = float(max(response['av_pred']))\n",
    "                av_pred_value = float(max(av_pred))\n",
    "                dictionary = {'label': label, 'av_pred': av_pred_value,'other_response':response}\n",
    "            dictionary.update({'timeExtract':time_extract})\n",
    "            self.log.debug('Final Pred label is: {}'.format(label))\n",
    "            dictionary.update({self.label_meaning:self.label_meaning_map.get(label,'null')})\n",
    "            return dictionary\n",
    "\n",
    "\n",
    "\n",
    "class ClassifierOther:\n",
    "    def __init__(self, **model):\n",
    "        \"\"\"\n",
    "        suggested parameters:\n",
    "        svc, logistic, nb, jieba_path, tfidf\n",
    "        \"\"\"\n",
    "        self.log = None\n",
    "        self._load_model(**model)\n",
    "        self._load_attributes(**model)\n",
    "        \n",
    "        \n",
    "    def _load_model(self,**model):\n",
    "        self.svc = model.get('svc')\n",
    "        self.logistic = model.get('logistic')\n",
    "        self.nb = model.get('nb')\n",
    "        self.tfidf = model.get('tfidf')\n",
    "        # load jieba\n",
    "        jieba_path = model.get('jieba_path')\n",
    "        if jieba_path is not None:\n",
    "            jieba.load_userdict(jieba_path)\n",
    "        \n",
    "            \n",
    "    def _load_attributes(self, **model):\n",
    "        self.label_mapping = model.get('possible_label')\n",
    "        self.label_mapping = sorted(list(set(self.label_mapping)))\n",
    "        \n",
    "    \n",
    "    def classify(self, sentence):\n",
    "        \"\"\"\n",
    "        input: sentence\n",
    "        output: result(dictionary)\n",
    "        \"\"\"\n",
    "        if self.log is None:\n",
    "            self.log = Logger(self.__class__.__name__,level=ENV.MODEL_LOG_LEVEL.value).logger\n",
    "        sentence = jieba.cut(sentence, cut_all = False)\n",
    "        sentence = ' '.join(sentence)\n",
    "        matrix = self.tfidf.transform([sentence])\n",
    "        self.log.debug('In transfered tfidf, the number of words in vocalbulary is: {}'.format(len(matrix.data)))\n",
    "        \n",
    "        result = np.vstack((self.svc.predict_proba(matrix),\n",
    "                                 self.logistic.predict_proba(matrix),\n",
    "                                 self.nb.predict_proba(matrix)))\n",
    "        \n",
    "        av_pred = np.mean(result, axis = 0)\n",
    "        max_pred = np.max(av_pred, axis = 0)\n",
    "        max_arg = np.argmax(av_pred)\n",
    "        \n",
    "        label = max_arg\n",
    "        label = self.label_mapping[label]\n",
    "            \n",
    "        dictionary = {'label': label, 'pred_prob': result, 'av_pred': av_pred}\n",
    "        self.log.debug('Possible labels are: {}'.format(self.label_mapping))\n",
    "        self.log.debug('Other- Final Pred label is: {}'.format(dictionary['label']))\n",
    "        self.log.debug('Other- svc,logistic,nb result:\\n {}'.format(dictionary['pred_prob']))\n",
    "        self.log.debug('Other- ave result:\\n {}'.format(dictionary['av_pred']))\n",
    "        return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T03:17:19.844588Z",
     "start_time": "2018-08-20T03:17:19.838860Z"
    }
   },
   "outputs": [],
   "source": [
    "model_list = {\n",
    "                'IDClassifier':IDClassifier, \n",
    "                  'CutDebt':CutDebt, \n",
    "                  'WillingToPay':WillingToPay,\n",
    "                  'IfKnowDebtor':IfKnowDebtor,\n",
    "                  'Installment':Installment,\n",
    "                  'ConfirmLoan':ConfirmLoan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T03:17:20.684643Z",
     "start_time": "2018-08-20T03:17:20.649938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3950, 2)\n",
      "(1408, 8)\n",
      "(16, 9)\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "import jieba\n",
    "jieba.load_userdict(\"../../code/WordCut/userdict.txt\")\n",
    "\n",
    "import gc\n",
    "import pickle\n",
    "path = '../../data/others/'\n",
    "\n",
    "# load cleaned other data\n",
    "other_non109 = pd.read_csv('../../data/others/cleaned_mock_up_data_non109.csv')\n",
    "other_109 = pd.read_csv('../../data/others/cleaned_mock_up_data_109.csv')\n",
    "strategy_mat = pd.read_csv(path + 'strategy_mat.csv', encoding='utf8')\n",
    "\n",
    "print(other_non109.shape)\n",
    "print(other_109.shape)\n",
    "print(strategy_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T03:17:21.394726Z",
     "start_time": "2018-08-20T03:17:21.377063Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_other_data(df_non109,df_109,strategy_mat,classifier):\n",
    "    possible_label = sorted(list(set(strategy_mat[strategy_mat[classifier]==0]['label'].values)))\n",
    "    train_data_non109 = df_non109[df_non109['label'].apply(lambda x: x in possible_label)]\n",
    "    train_data_109 = df_109[df_109[classifier]==0]\n",
    "    data = pd.concat([train_data_non109,train_data_109],ignore_index=True,sort=True)\n",
    "    return data\n",
    "\n",
    "def train_other_model(other_data,save_path,model):\n",
    "    phrase_vectorizer_other = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                strip_accents='unicode', \n",
    "                                max_features=100000, \n",
    "                                analyzer='word',\n",
    "                                sublinear_tf=True,\n",
    "                                token_pattern=r'\\w{1,}')\n",
    "\n",
    "    print('fitting phrase')\n",
    "    phrase_vectorizer_other.fit(other_data.text)\n",
    "\n",
    "    print('transform phrase')\n",
    "    phrase = phrase_vectorizer_other.transform(other_data.text)\n",
    "\n",
    "\n",
    "    # linear svc\n",
    "    l_svc = LinearSVC()\n",
    "    lsvc = CalibratedClassifierCV(l_svc) \n",
    "    lsvc.fit(phrase, other_data.label)\n",
    "\n",
    "\n",
    "    # logistic\n",
    "    log_r = LogisticRegression()\n",
    "    log_r.fit(phrase, other_data.label)\n",
    "\n",
    "\n",
    "    # Naive Bayes\n",
    "    naive_b = MultinomialNB()\n",
    "    naive_b.fit(phrase, other_data.label)\n",
    "    \n",
    "    print('finish training others')\n",
    "    \n",
    "    \n",
    "    # other wrapper \n",
    "    other_model = ClassifierOther(svc=lsvc, logistic=log_r, nb=naive_b, tfidf=phrase_vectorizer_other, jieba_path='../WordCut/userdict.txt',possible_label=lsvc.classes_)\n",
    "    \n",
    "    # Saving:\n",
    "    evl_path = save_path.format(model,model)\n",
    "    print('saving to path: {}'.format(evl_path))\n",
    "#     pickle.dump(other_model, open(evl_path, \"wb\"))\n",
    "    return other_model\n",
    "    \n",
    "    \n",
    "def train_main_model(df,save_path,model,other_model):\n",
    "    # get tfidf\n",
    "    \n",
    "    phrase_vectorizer = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                    strip_accents='unicode', \n",
    "                                    max_features=100000, \n",
    "                                    analyzer='word',\n",
    "                                    sublinear_tf=True,\n",
    "                                    token_pattern=r'\\w{1,}')\n",
    "\n",
    "    print('fitting phrase')\n",
    "    phrase_vectorizer.fit(df.split_text)\n",
    "\n",
    "    print('transform phrase')\n",
    "    phrase = phrase_vectorizer.transform(df.split_text)\n",
    "    \n",
    "    # linear svc\n",
    "    l_svc = LinearSVC()\n",
    "    lsvc = CalibratedClassifierCV(l_svc) \n",
    "    lsvc.fit(phrase, df.label)\n",
    "    \n",
    "    \n",
    "    # logistic\n",
    "    log_r = LogisticRegression()\n",
    "    log_r.fit(phrase, df.label)\n",
    "    \n",
    "    \n",
    "    # Naive Bayes\n",
    "    naive_b = MultinomialNB()\n",
    "    naive_b.fit(phrase, df.label)\n",
    "    print('finish training')\n",
    "    \n",
    "    main_model = model_list[model](svc=lsvc, logistic=log_r, nb=naive_b, tfidf=phrase_vectorizer, other=other_model,  jieba_path='../WordCut/userdict.txt')\n",
    "    evl_path = save_path.format(model,model)\n",
    "#     pickle.dump(main_model, open(evl_path, \"wb\"))\n",
    "    print('saving to path: {}'.format(evl_path))\n",
    "    return main_model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Other Model + Main Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train IDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T03:20:23.680562Z",
     "start_time": "2018-08-20T03:20:21.520236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting phrase\n",
      "transform phrase\n",
      "finish training others\n",
      "saving to path: ../../../classifier/saved_model/Installment/other_flow/Installment.pkl\n",
      "=====  Installment =======\n",
      "2    4703\n",
      "0    3726\n",
      "1    2375\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "Time Zone is set from ENV: Asia/Shanghai\n",
      "saving to path: ../../../classifier/saved_model/Installment/main_flow/Installment.pkl\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# each_model = 'IDClassifier' \n",
    "save_path_other = '../../../classifier/saved_model/{}/other_flow/{}.pkl'\n",
    "save_path_main = '../../../classifier/saved_model/{}/main_flow/{}.pkl'\n",
    "\n",
    "each_model = 'Installment'\n",
    "other_data = get_other_data(other_non109,other_109,strategy_mat,each_model)\n",
    "other_data = other_data.sample(frac=1,random_state=19)\n",
    "\n",
    "other_model = train_other_model(other_data,save_path_other,each_model)\n",
    "\n",
    "# train main\n",
    "df_main = pd.read_csv('../../data/{}/cleaned_mock_up_data.csv'.format(each_model))\n",
    "other_label = int(max(set(df_main.label)) + 1)\n",
    "ava_others = other_data.rename({'text':'split_text'},axis=1)\n",
    "ava_others['label'] = other_label\n",
    "df_main = pd.concat([df_main,ava_others],sort=True)\n",
    "df_main = df_main.sample(frac=1,random_state=6).reset_index(drop=True)\n",
    "print('=====  {} ======='.format(each_model))\n",
    "print(df_main.label.value_counts())\n",
    "clf = train_main_model(df_main,save_path_main,each_model,other_model)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T03:20:43.991625Z",
     "start_time": "2018-08-20T03:20:43.966099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'av_pred': 0.9679038176105955,\n",
       " 'other_response': None,\n",
       " 'timeExtract': [{'pattern': '后天下午2点',\n",
       "   'time': datetime.datetime(2018, 8, 22, 14, 0, tzinfo=<DstTzInfo 'Asia/Shanghai' CST+8:00:00 STD>),\n",
       "   'gapS': 182356.032478,\n",
       "   'gapH': 50.654453466111114}],\n",
       " 'ifAcceptInstallment': 'n'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classify('后天下午2点就还')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
