{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "After running K fold to select those data which are predicted into a wrong category, we implemented mannual recorrection. This script is to apply those correction to the original files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T21:09:40.495802Z",
     "start_time": "2018-07-18T21:09:40.492804Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T21:11:01.857491Z",
     "start_time": "2018-07-18T21:11:01.775236Z"
    }
   },
   "outputs": [],
   "source": [
    "model_list = ['CutDebt','IDClassifier','IfKnowDebtor','Installment','ConfirmLoan','WillingToPay']\n",
    "# model_list = ['CutDebt','IfKnowDebtor','Installment','ConfirmLoan','WillingToPay']\n",
    "df_others = pd.read_csv('../../MLModel/data/others/irrelevant_response_training_set.csv')\n",
    "df_other_matrix = pd.read_csv('../../MLModel/data/others/strategy_mat.csv')\n",
    "num2text = df_other_matrix.set_index('label').category.drop_duplicates().to_dict()\n",
    "\n",
    "df_all_original = {}\n",
    "for each in model_list:\n",
    "    df_all_original[each] = pd.read_csv('../../MLModel/data/{}/mock_up_data1.csv'.format(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T21:09:49.516694Z",
     "start_time": "2018-07-18T21:09:42.193829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutDebt -- 4128\n",
      "length of other: 4687\n",
      "CutDebt -- 3874\n",
      "length of other: 4928\n",
      "CutDebt -- 4168\n",
      "case 1 has data : 225\n",
      "case 2 has data : 94\n",
      "case 3 has data : 294\n",
      "case 4 has data : 21\n",
      "total corrected is: 634\n",
      "total file length is: 1371\n",
      "IDClassifier -- 2743\n",
      "length of other: 4928\n",
      "IDClassifier -- 2354\n",
      "length of other: 5302\n",
      "IDClassifier -- 2437\n",
      "case 1 has data : 374\n",
      "case 2 has data : 48\n",
      "case 3 has data : 83\n",
      "case 4 has data : 0\n",
      "total corrected is: 505\n",
      "total file length is: 1008\n",
      "IfKnowDebtor -- 2660\n",
      "length of other: 5302\n",
      "IfKnowDebtor -- 2554\n",
      "length of other: 5405\n",
      "IfKnowDebtor -- 2649\n",
      "case 1 has data : 103\n",
      "case 2 has data : 61\n",
      "case 3 has data : 95\n",
      "case 4 has data : 0\n",
      "total corrected is: 259\n",
      "total file length is: 605\n",
      "Installment -- 4171\n",
      "length of other: 5405\n",
      "Installment -- 3926\n",
      "length of other: 5643\n",
      "Installment -- 4294\n",
      "case 1 has data : 233\n",
      "case 2 has data : 262\n",
      "case 3 has data : 368\n",
      "case 4 has data : 7\n",
      "total corrected is: 870\n",
      "total file length is: 1655\n",
      "ConfirmLoan -- 1133\n",
      "length of other: 5643\n",
      "ConfirmLoan -- 1115\n",
      "length of other: 5661\n",
      "ConfirmLoan -- 1269\n",
      "case 1 has data : 18\n",
      "case 2 has data : 29\n",
      "case 3 has data : 154\n",
      "case 4 has data : 0\n",
      "total corrected is: 201\n",
      "total file length is: 476\n",
      "WillingToPay -- 6278\n",
      "length of other: 5661\n",
      "WillingToPay -- 5494\n",
      "length of other: 6392\n",
      "WillingToPay -- 5564\n",
      "case 1 has data : 731\n",
      "case 2 has data : 860\n",
      "case 3 has data : 70\n",
      "case 4 has data : 0\n",
      "total corrected is: 1661\n",
      "total file length is: 2733\n"
     ]
    }
   ],
   "source": [
    "for model in model_list:\n",
    "    df_correction = pd.read_csv('../../MLModel/data/{}/labelNeedsCorrections.csv'.format(model))\n",
    "    other_label = max(df_all_original[model].label)\n",
    "    non_other_label = set(df_all_original[model].label.values) - set([other_label])\n",
    "    df_all_original[model] = df_all_original[model][df_all_original[model].label != other_label]\n",
    "    print('{} -- {}'.format(model,len(df_all_original[model])))\n",
    "    print('length of other: {}'.format(len(df_others)))\n",
    "    append_other_text = []\n",
    "    append_other_category = []\n",
    "\n",
    "    append_function_text = {}\n",
    "    append_function_category = {}\n",
    "\n",
    "    original_remove_index = {}\n",
    "\n",
    "    count_case1 = 0\n",
    "    count_case2 = 0\n",
    "    count_case3 = 0\n",
    "    count_case4 = 0\n",
    "    for index in range(len(df_correction)):\n",
    "        ############ get data #####################\n",
    "        cur_data = df_correction.iloc[index]\n",
    "        data_from = cur_data['from']\n",
    "        label = cur_data['label']\n",
    "        original_text = cur_data['original_text']\n",
    "        new_label = cur_data['new_label']\n",
    "        ########### apply to original files #######\n",
    "        if model in ['CutDebt','Installment'] and new_label == 110:\n",
    "            count_case4 += 1\n",
    "            if label in non_other_label:\n",
    "                ### insert into others\n",
    "                append_other_text.append(original_text)\n",
    "                append_other_category.append(num2text[new_label])\n",
    "                ### remove from original\n",
    "                rindex = df_all_original[data_from][(df_all_original[data_from].label==label) &(df_all_original[data_from].split_text==original_text)].index.values\n",
    "                if original_remove_index.get(data_from) is None:\n",
    "                    original_remove_index[data_from] = []\n",
    "                original_remove_index[data_from].extend(list(rindex))\n",
    "            else:\n",
    "                ### update others\n",
    "                rindex = df_others[df_others['文本']==original_text].index.values\n",
    "                if len(rindex) == 0:\n",
    "                    ### insert into others\n",
    "                    append_other_text.append(original_text)\n",
    "                    append_other_category.append(num2text[new_label])\n",
    "                else:    \n",
    "                    df_others.loc[rindex,'类别'] = num2text[110]\n",
    "            continue\n",
    "        if label in non_other_label and new_label >= 100:\n",
    "            count_case1 += 1\n",
    "            ### insert into others\n",
    "            append_other_text.append(original_text)\n",
    "            append_other_category.append(num2text[new_label])\n",
    "\n",
    "            ### remove from original\n",
    "            rindex = df_all_original[data_from][(df_all_original[data_from].label==label) &(df_all_original[data_from].split_text==original_text)].index.values\n",
    "            if original_remove_index.get(data_from) is None:\n",
    "                original_remove_index[data_from] = []\n",
    "            original_remove_index[data_from].extend(list(rindex))\n",
    "\n",
    "\n",
    "        elif label in non_other_label and new_label in non_other_label and label!= new_label:\n",
    "            count_case2 += 1\n",
    "            # update original data\n",
    "            indexes = df_all_original[data_from][(df_all_original[data_from].label==label) &(df_all_original[data_from].split_text==original_text)].index.values\n",
    "            df_all_original[data_from].loc[indexes,'label'] = new_label\n",
    "\n",
    "        elif label == other_label and new_label in non_other_label:\n",
    "            count_case3+=1\n",
    "            if append_function_text.get(model) is None:\n",
    "                append_function_text[model]=[]\n",
    "                append_function_category[model]=[]\n",
    "            append_function_text[model].append(original_text)\n",
    "            append_function_category[model].append(new_label)\n",
    "\n",
    "    others_append = pd.DataFrame({'文本':append_other_text,'类别':append_other_category})\n",
    "    function_append = pd.DataFrame({'split_text':append_function_text,'label':append_function_category})\n",
    "\n",
    "    #### apply to self and others\n",
    "    #### drop logic\n",
    "    for each_key in original_remove_index:\n",
    "        indexes = original_remove_index[each_key]\n",
    "        df_all_original[each_key] = df_all_original[each_key].drop(index=indexes)\n",
    "        print('{} -- {}'.format(each_key,len(df_all_original[each_key])))\n",
    "    ####end drop\n",
    "    df_others = pd.concat([df_others,others_append],sort=True).reset_index(drop=True)\n",
    "    print('length of other: {}'.format(len(df_others)))\n",
    "    for each_key in append_function_text:\n",
    "        function_append = pd.DataFrame({'split_text':append_function_text[each_key],\n",
    "                                        'label':append_function_category[each_key]})\n",
    "\n",
    "        df_all_original[each_key] = pd.concat([df_all_original[each_key],function_append],sort=True).reset_index(drop=True)\n",
    "        print('{} -- {}'.format(each_key,len(df_all_original[each_key])))\n",
    "\n",
    "    print('case 1 has data : {}'.format(count_case1))\n",
    "    print('case 2 has data : {}'.format(count_case2))\n",
    "    print('case 3 has data : {}'.format(count_case3))\n",
    "    print('case 4 has data : {}'.format(count_case4))\n",
    "    print('total corrected is: {}'.format(count_case1+count_case2+count_case3+count_case4))\n",
    "    print('total file length is: {}'.format(len(df_correction)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T21:11:06.010177Z",
     "start_time": "2018-07-18T21:11:05.979145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutDebt\n",
      "1    2351\n",
      "0    1817\n",
      "Name: label, dtype: int64\n",
      "===================\n",
      "IDClassifier\n",
      "1    1261\n",
      "0    1176\n",
      "Name: label, dtype: int64\n",
      "===================\n",
      "IfKnowDebtor\n",
      "0    1413\n",
      "1    1236\n",
      "Name: label, dtype: int64\n",
      "===================\n",
      "Installment\n",
      "1    2422\n",
      "0    1872\n",
      "Name: label, dtype: int64\n",
      "===================\n",
      "ConfirmLoan\n",
      "0    718\n",
      "1    551\n",
      "Name: label, dtype: int64\n",
      "===================\n",
      "WillingToPay\n",
      "1    2677\n",
      "0    1803\n",
      "2    1084\n",
      "Name: label, dtype: int64\n",
      "===================\n"
     ]
    }
   ],
   "source": [
    "model_list = ['CutDebt','IDClassifier','IfKnowDebtor','Installment','ConfirmLoan','WillingToPay']\n",
    "for model in model_list:\n",
    "    print(model)\n",
    "    print(df_all_original[model].label.value_counts())\n",
    "    print('===================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T21:09:55.674594Z",
     "start_time": "2018-07-18T21:09:55.669109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6392\n"
     ]
    }
   ],
   "source": [
    "print(len(df_others))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T21:10:57.185696Z",
     "start_time": "2018-07-18T21:10:57.045013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutDebt\n",
      "IDClassifier\n",
      "IfKnowDebtor\n",
      "Installment\n",
      "ConfirmLoan\n",
      "WillingToPay\n"
     ]
    }
   ],
   "source": [
    "# Save \n",
    "model_list = ['CutDebt','IDClassifier','IfKnowDebtor','Installment','ConfirmLoan','WillingToPay']\n",
    "for model in model_list:\n",
    "    df = df_all_original[model].copy()\n",
    "    df['label'] = df['label'].astype('int')\n",
    "    df.to_csv('../../MLModel/data/{}/mock_up_data1.csv'.format(model),index=False,encoding='utf8')\n",
    "    print(model)\n",
    "df_others.to_csv('../../MLModel/data/others/irrelevant_response_training_set.csv',index=False,encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T20:17:21.816747Z",
     "start_time": "2018-07-18T20:17:21.773580Z"
    }
   },
   "source": [
    "# Expriment - no other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T20:41:48.901229Z",
     "start_time": "2018-07-18T20:41:48.813554Z"
    }
   },
   "outputs": [],
   "source": [
    "model_list = ['CutDebt','IDClassifier','IfKnowDebtor','Installment','ConfirmLoan','WillingToPay']\n",
    "# model_list = ['CutDebt','IfKnowDebtor','Installment','ConfirmLoan','WillingToPay']\n",
    "df_others = pd.read_csv('../../MLModel/data/others/irrelevant_response_training_set.csv')\n",
    "df_other_matrix = pd.read_csv('../../MLModel/data/others/strategy_mat.csv')\n",
    "num2text = df_other_matrix.set_index('label').category.drop_duplicates().to_dict()\n",
    "\n",
    "df_all_original = {}\n",
    "for each in model_list:\n",
    "    df_all_original[each] = pd.read_csv('../../MLModel/data/{}/mock_up_data2.csv'.format(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T20:42:31.669828Z",
     "start_time": "2018-07-18T20:42:25.460886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutDebt -- 4166\n",
      "length of other: 8096\n",
      "CutDebt -- 4166\n",
      "length of other: 8336\n",
      "case 1 has data : 225\n",
      "case 2 has data : 94\n",
      "case 3 has data : 0\n",
      "case 4 has data : 21\n",
      "total corrected is: 340\n",
      "total file length is: 1371\n",
      "IDClassifier -- 2435\n",
      "length of other: 8336\n",
      "IDClassifier -- 2435\n",
      "length of other: 8710\n",
      "case 1 has data : 374\n",
      "case 2 has data : 48\n",
      "case 3 has data : 0\n",
      "case 4 has data : 0\n",
      "total corrected is: 422\n",
      "total file length is: 1008\n",
      "IfKnowDebtor -- 2649\n",
      "length of other: 8710\n",
      "IfKnowDebtor -- 2649\n",
      "length of other: 8813\n",
      "case 1 has data : 103\n",
      "case 2 has data : 61\n",
      "case 3 has data : 0\n",
      "case 4 has data : 0\n",
      "total corrected is: 164\n",
      "total file length is: 605\n",
      "Installment -- 4291\n",
      "length of other: 8813\n",
      "Installment -- 4291\n",
      "length of other: 9051\n",
      "case 1 has data : 233\n",
      "case 2 has data : 262\n",
      "case 3 has data : 0\n",
      "case 4 has data : 7\n",
      "total corrected is: 502\n",
      "total file length is: 1655\n",
      "ConfirmLoan -- 1269\n",
      "length of other: 9051\n",
      "ConfirmLoan -- 1269\n",
      "length of other: 9069\n",
      "case 1 has data : 18\n",
      "case 2 has data : 29\n",
      "case 3 has data : 0\n",
      "case 4 has data : 0\n",
      "total corrected is: 47\n",
      "total file length is: 476\n",
      "WillingToPay -- 5557\n",
      "length of other: 9069\n",
      "WillingToPay -- 5557\n",
      "length of other: 9800\n",
      "case 1 has data : 731\n",
      "case 2 has data : 860\n",
      "case 3 has data : 0\n",
      "case 4 has data : 0\n",
      "total corrected is: 1591\n",
      "total file length is: 2733\n"
     ]
    }
   ],
   "source": [
    "for model in model_list:\n",
    "    df_correction = pd.read_csv('../../MLModel/data/{}/labelNeedsCorrections.csv'.format(model))\n",
    "    non_other_label = set(df_all_original[model].label.values) \n",
    "    print('{} -- {}'.format(model,len(df_all_original[model])))\n",
    "    print('length of other: {}'.format(len(df_others)))\n",
    "    append_other_text = []\n",
    "    append_other_category = []\n",
    "\n",
    "    append_function_text = {}\n",
    "    append_function_category = {}\n",
    "\n",
    "    original_remove_index = {}\n",
    "\n",
    "    count_case1 = 0\n",
    "    count_case2 = 0\n",
    "    count_case3 = 0\n",
    "    count_case4 = 0\n",
    "    for index in range(len(df_correction)):\n",
    "        ############ get data #####################\n",
    "        cur_data = df_correction.iloc[index]\n",
    "        data_from = cur_data['from']\n",
    "        label = cur_data['label']\n",
    "        original_text = cur_data['original_text']\n",
    "        new_label = cur_data['new_label']\n",
    "        ########### apply to original files #######\n",
    "        if model in ['CutDebt','Installment'] and new_label == 110:\n",
    "            count_case4 += 1\n",
    "            if label in non_other_label:\n",
    "                ### insert into others\n",
    "                append_other_text.append(original_text)\n",
    "                append_other_category.append(num2text[new_label])\n",
    "                ### remove from original\n",
    "                rindex = df_all_original[data_from][(df_all_original[data_from].label==label) &(df_all_original[data_from].split_text==original_text)].index.values\n",
    "                if original_remove_index.get(data_from) is None:\n",
    "                    original_remove_index[data_from] = []\n",
    "                original_remove_index[data_from].extend(list(rindex))\n",
    "            else:\n",
    "                ### update others\n",
    "                rindex = df_others[df_others['文本']==original_text].index.values\n",
    "                if len(rindex) == 0:\n",
    "                    ### insert into others\n",
    "                    append_other_text.append(original_text)\n",
    "                    append_other_category.append(num2text[new_label])\n",
    "                else:    \n",
    "                    df_others.loc[rindex,'类别'] = num2text[110]\n",
    "            continue\n",
    "        if label in non_other_label and new_label >= 100:\n",
    "            count_case1 += 1\n",
    "            ### insert into others\n",
    "            append_other_text.append(original_text)\n",
    "            append_other_category.append(num2text[new_label])\n",
    "\n",
    "            ### remove from original\n",
    "            rindex = df_all_original[data_from][(df_all_original[data_from].label==label) &(df_all_original[data_from].split_text==original_text)].index.values\n",
    "            if original_remove_index.get(data_from) is None:\n",
    "                original_remove_index[data_from] = []\n",
    "            original_remove_index[data_from].extend(list(rindex))\n",
    "\n",
    "\n",
    "        elif label in non_other_label and new_label in non_other_label and label!= new_label:\n",
    "            count_case2 += 1\n",
    "            # update original data\n",
    "            indexes = df_all_original[data_from][(df_all_original[data_from].label==label) &(df_all_original[data_from].split_text==original_text)].index.values\n",
    "            df_all_original[data_from].loc[indexes,'label'] = new_label\n",
    "\n",
    "        \n",
    "\n",
    "    others_append = pd.DataFrame({'文本':append_other_text,'类别':append_other_category})\n",
    "    function_append = pd.DataFrame({'split_text':append_function_text,'label':append_function_category})\n",
    "\n",
    "    #### apply to self and others\n",
    "    #### drop logic\n",
    "    for each_key in original_remove_index:\n",
    "        indexes = original_remove_index[each_key]\n",
    "        df_all_original[each_key] = df_all_original[each_key].drop(index=indexes)\n",
    "        print('{} -- {}'.format(each_key,len(df_all_original[each_key])))\n",
    "    ####end drop\n",
    "    df_others = pd.concat([df_others,others_append],sort=True).reset_index(drop=True)\n",
    "    print('length of other: {}'.format(len(df_others)))\n",
    "    for each_key in append_function_text:\n",
    "        function_append = pd.DataFrame({'split_text':append_function_text[each_key],\n",
    "                                        'label':append_function_category[each_key]})\n",
    "\n",
    "        df_all_original[each_key] = pd.concat([df_all_original[each_key],function_append],sort=True).reset_index(drop=True)\n",
    "        print('{} -- {}'.format(each_key,len(df_all_original[each_key])))\n",
    "\n",
    "    print('case 1 has data : {}'.format(count_case1))\n",
    "    print('case 2 has data : {}'.format(count_case2))\n",
    "    print('case 3 has data : {}'.format(count_case3))\n",
    "    print('case 4 has data : {}'.format(count_case4))\n",
    "    print('total corrected is: {}'.format(count_case1+count_case2+count_case3+count_case4))\n",
    "    print('total file length is: {}'.format(len(df_correction)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resotre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T03:00:57.489526Z",
     "start_time": "2018-07-19T03:00:57.382039Z"
    }
   },
   "outputs": [],
   "source": [
    "model_list = ['CutDebt','IDClassifier','IfKnowDebtor','Installment','ConfirmLoan','WillingToPay']\n",
    "\n",
    "\n",
    "\n",
    "df_need_correction_original = {}\n",
    "df_need_correction_new = {}\n",
    "for each in model_list:\n",
    "    df_need_correction_original[each] = pd.read_csv('../../MLModel/data/{}/labelNeedsCorrections1.csv'.format(each))\n",
    "    df_need_correction_new[each] = pd.read_csv('../../MLModel/data/{}/labelNeedsCorrections.csv'.format(each))\n",
    "    df_all_original[each] = pd.read_csv('../../MLModel/data/{}/mock_up_data1.csv'.format(each))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T03:11:23.241630Z",
     "start_time": "2018-07-19T03:11:09.931174Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutDebt\n",
      "79\n",
      "=========================\n",
      "IDClassifier\n",
      "72\n",
      "=========================\n",
      "IfKnowDebtor\n",
      "112\n",
      "=========================\n",
      "Installment\n",
      "263\n",
      "=========================\n",
      "ConfirmLoan\n",
      "8\n",
      "=========================\n",
      "WillingToPay\n",
      "160\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "index_remove = {}\n",
    "for model in model_list:   \n",
    "    \n",
    "    df_tmp = df_need_correction_new[model].copy()\n",
    "    for index in range(len(df_need_correction_original[model])):\n",
    "        data = df_need_correction_original[model].iloc[index]\n",
    "        data_from = data['from']\n",
    "        label = data['label']\n",
    "        original_text = data['original_text']\n",
    "        filterd = df_tmp[(df_tmp['from'] == data_from) & (df_tmp.label == label) & (df_tmp.original_text == original_text) ]\n",
    "        # if not in original\n",
    "        if len(filterd) == 0:\n",
    "            if data_from in model_list:\n",
    "                #add key to index_remove\n",
    "                df_ori = df_all_original[data_from].copy()\n",
    "                if index_remove.get(data_from) is None:\n",
    "                    index_remove[data_from] = []\n",
    "                \n",
    "                \n",
    "                #check in original     \n",
    "                filterd_ori = df_ori[ (df_ori.label == label) & (df_ori.split_text == original_text) ]\n",
    "                if len(filterd_ori) > 0:\n",
    "                    index_remove[data_from].extend(list(filterd_ori.index.values))\n",
    "            \n",
    "    print(model)\n",
    "    print(len(index_remove[model]))\n",
    "    print('=========================')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T03:16:16.448708Z",
     "start_time": "2018-07-19T03:16:16.417182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before droping! CutDebt -- 4168\n",
      "After droping! CutDebt -- 4111\n",
      "Before droping! IDClassifier -- 2437\n",
      "After droping! IDClassifier -- 2367\n",
      "Before droping! IfKnowDebtor -- 2649\n",
      "After droping! IfKnowDebtor -- 2547\n",
      "Before droping! Installment -- 4294\n",
      "After droping! Installment -- 4218\n",
      "Before droping! ConfirmLoan -- 1269\n",
      "After droping! ConfirmLoan -- 1261\n",
      "Before droping! WillingToPay -- 5564\n",
      "After droping! WillingToPay -- 5436\n"
     ]
    }
   ],
   "source": [
    "#### drop logic\n",
    "for each_key in index_remove:\n",
    "    print('Before droping! {} -- {}'.format(each_key,len(df_all_original[each_key])))\n",
    "    indexes = index_remove[each_key]\n",
    "    df_all_original[each_key] = df_all_original[each_key].drop(index=indexes)\n",
    "    print('After droping! {} -- {}'.format(each_key,len(df_all_original[each_key])))\n",
    "####end drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T03:19:22.524163Z",
     "start_time": "2018-07-19T03:19:22.371577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutDebt\n",
      "1    2327\n",
      "0    1784\n",
      "Name: label, dtype: int64\n",
      "===========\n",
      "IDClassifier\n",
      "1    1234\n",
      "0    1133\n",
      "Name: label, dtype: int64\n",
      "===========\n",
      "IfKnowDebtor\n",
      "0    1363\n",
      "1    1184\n",
      "Name: label, dtype: int64\n",
      "===========\n",
      "Installment\n",
      "1    2379\n",
      "0    1839\n",
      "Name: label, dtype: int64\n",
      "===========\n",
      "ConfirmLoan\n",
      "0    713\n",
      "1    548\n",
      "Name: label, dtype: int64\n",
      "===========\n",
      "WillingToPay\n",
      "1    2620\n",
      "0    1778\n",
      "2    1038\n",
      "Name: label, dtype: int64\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "# Save \n",
    "model_list = ['CutDebt','IDClassifier','IfKnowDebtor','Installment','ConfirmLoan','WillingToPay']\n",
    "for model in model_list:\n",
    "    df = df_all_original[model].copy()\n",
    "    df['label'] = df['label'].astype('int')\n",
    "    df.to_csv('../../MLModel/data/{}/mock_up_data1.csv'.format(model),index=False,encoding='utf8')\n",
    "    print(model)\n",
    "    print(df.label.value_counts())\n",
    "    print('===========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
