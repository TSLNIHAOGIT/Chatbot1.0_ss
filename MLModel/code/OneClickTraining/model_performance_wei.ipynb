{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T03:55:14.907206Z",
     "start_time": "2018-07-10T03:55:14.054339Z"
    }
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "# import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "import sys,os\n",
    "from all_model_py import CutDebt, IDClassifier, IfKnowDebtor, Installment, WillingToPay, ConfirmLoan\n",
    "\n",
    "sys.path.append('../../../Lib/')\n",
    "from model_matrix import eval_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T03:55:19.335037Z",
     "start_time": "2018-07-10T03:55:19.330517Z"
    }
   },
   "outputs": [],
   "source": [
    "def sub_df(df,sets,target='label'):\n",
    "    result = pd.DataFrame()\n",
    "    for each in sets:\n",
    "        result = pd.concat([result,df[df[target]==each]])\n",
    "#     print(result[target].value_counts())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T03:55:20.158269Z",
     "start_time": "2018-07-10T03:55:20.100468Z"
    }
   },
   "outputs": [],
   "source": [
    "others = pd.read_csv('../../data/others/cleaned_mock_up_data.csv')\n",
    "other_matrix = pd.read_csv('../../data/others/strategy_mat.csv')\n",
    "target = 'label'\n",
    "save_path = '../../savedModel/{}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CutDebt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T05:27:04.373712Z",
     "start_time": "2018-07-10T05:26:55.419487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====  CutDebt =======\n",
      "0    4105\n",
      "2    2819\n",
      "1    2144\n",
      "Name: label, dtype: int64\n",
      "begin training!\n",
      "fitting phrase\n",
      "transform phrase\n",
      "======== Linear SVC =======\n",
      "                pred_0      pred_1      pred_2    recall\n",
      "actual_0   1092.000000   63.000000  104.000000  0.867355\n",
      "actual_1     57.000000  496.000000   79.000000  0.784810\n",
      "actual_2     88.000000   94.000000  648.000000  0.780723\n",
      "precision     0.882781    0.759571    0.779783  0.821757\n",
      "======== logistic =======\n",
      "                pred_0      pred_1      pred_2    recall\n",
      "actual_0   1093.000000   52.000000  114.000000  0.868149\n",
      "actual_1     85.000000  457.000000   90.000000  0.723101\n",
      "actual_2     95.000000   74.000000  661.000000  0.796386\n",
      "precision     0.858602    0.783877    0.764162  0.812569\n",
      "======== Naive Bayes =======\n",
      "                pred_0      pred_1   pred_2    recall\n",
      "actual_0   1163.000000   37.000000   59.000  0.923749\n",
      "actual_1    124.000000  441.000000   67.000  0.697785\n",
      "actual_2    180.000000   56.000000  594.000  0.715663\n",
      "precision     0.792774    0.825843    0.825  0.807791\n",
      "======== SVM =======\n",
      "                pred_0     pred_1      pred_2    recall\n",
      "actual_0   1093.000000   60.00000  106.000000  0.868149\n",
      "actual_1     62.000000  492.00000   78.000000  0.778481\n",
      "actual_2     93.000000   88.00000  649.000000  0.781928\n",
      "precision     0.875801    0.76875    0.779112  0.821022\n",
      "======== Random Forest =======\n",
      "               pred_0      pred_1      pred_2    recall\n",
      "actual_0   1129.00000   54.000000   76.000000  0.896743\n",
      "actual_1    107.00000  443.000000   82.000000  0.700949\n",
      "actual_2    194.00000   85.000000  551.000000  0.663855\n",
      "precision     0.78951    0.761168    0.777151  0.780228\n"
     ]
    }
   ],
   "source": [
    "model = 'CutDebt'\n",
    "df = pd.read_csv('../../data/{}/cleaned_mock_up_data.csv'.format(model))\n",
    "other_label = max(set(df.label))\n",
    "# filter out other label\n",
    "df = df[df.label != other_label]\n",
    "# get availabel other labels\n",
    "other_set = set(other_matrix[other_matrix[model]==0].label.values)\n",
    "ava_others = sub_df(others,other_set)\n",
    "ava_others[target] = other_label\n",
    "ava_others = ava_others.rename({'text':'split_text'},axis=1)\n",
    "df = pd.concat([df,ava_others],sort=True)\n",
    "# df = df.sample(frac=1,).reset_index(drop=True)\n",
    "print('=====  {} ======='.format(model))\n",
    "print(df.label.value_counts())\n",
    "print('begin training!')\n",
    "train,val = train_test_split(df,test_size=0.3,train_size=0.7,random_state=19)\n",
    "\n",
    "\n",
    "\n",
    "# get tfidf\n",
    "phrase_vectorizer = TfidfVectorizer(\n",
    "                                ngram_range=(1,3),\n",
    "                                strip_accents='unicode', \n",
    "                                max_features=100000, \n",
    "                                analyzer='word',\n",
    "                                sublinear_tf=True,\n",
    "                                use_idf=True,\n",
    "                                norm='l2',\n",
    "                                token_pattern=r'\\w{1,}')\n",
    "\n",
    "print('fitting phrase')\n",
    "phrase_vectorizer.fit(train.split_text)\n",
    "\n",
    "print('transform phrase')\n",
    "phrase_train = phrase_vectorizer.transform(train.split_text)\n",
    "phrase_val = phrase_vectorizer.transform(val.split_text)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "l_svc = LinearSVC(C=1)\n",
    "lsvc = CalibratedClassifierCV(l_svc) \n",
    "lsvc.fit(phrase_train, train.label)\n",
    "val_pred = lsvc.predict(phrase_val)\n",
    "evl = eval_mat(val.label.values, val_pred)\n",
    "print('======== Linear SVC =======')\n",
    "print(evl)\n",
    "\n",
    "\n",
    "# logistic\n",
    "log_r = LogisticRegression()\n",
    "log_r.fit(phrase_train, train.label)\n",
    "val_pred = log_r.predict(phrase_val)\n",
    "evl = eval_mat(val.label.values, val_pred)\n",
    "print('======== logistic =======')\n",
    "print(evl)\n",
    "\n",
    "\n",
    "# Naive Bayes\n",
    "naive_b = MultinomialNB()\n",
    "naive_b.fit(phrase_train, train.label)\n",
    "val_pred = naive_b.predict(phrase_val)\n",
    "evl = eval_mat(val.label.values, val_pred)\n",
    "print('======== Naive Bayes =======')\n",
    "print(evl)\n",
    "\n",
    "# SVM\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(phrase_train, train.label)\n",
    "val_pred = svm.predict(phrase_val)\n",
    "evl = eval_mat(val.label.values, val_pred)\n",
    "print('======== SVM =======')\n",
    "print(evl)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(phrase_train, train.label)\n",
    "val_pred = rf.predict(phrase_val)\n",
    "evl = eval_mat(val.label.values, val_pred)\n",
    "print('======== Random Forest =======')\n",
    "print(evl)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "======== Linear SVC =======\n",
    "                pred_0      pred_1      pred_2    recall\n",
    "actual_0   1092.000000   63.000000  104.000000  0.867355\n",
    "actual_1     57.000000  496.000000   79.000000  0.784810\n",
    "actual_2     88.000000   94.000000  648.000000  0.780723\n",
    "precision     0.882781    0.759571    0.779783  0.821757\n",
    "======== logistic =======\n",
    "                pred_0      pred_1      pred_2    recall\n",
    "actual_0   1093.000000   52.000000  114.000000  0.868149\n",
    "actual_1     85.000000  457.000000   90.000000  0.723101\n",
    "actual_2     95.000000   74.000000  661.000000  0.796386\n",
    "precision     0.858602    0.783877    0.764162  0.812569\n",
    "======== Naive Bayes =======\n",
    "                pred_0      pred_1   pred_2    recall\n",
    "actual_0   1163.000000   37.000000   59.000  0.923749\n",
    "actual_1    124.000000  441.000000   67.000  0.697785\n",
    "actual_2    180.000000   56.000000  594.000  0.715663\n",
    "precision     0.792774    0.825843    0.825  0.807791\n",
    "======== SVM =======\n",
    "                pred_0     pred_1      pred_2    recall\n",
    "actual_0   1093.000000   60.00000  106.000000  0.868149\n",
    "actual_1     62.000000  492.00000   78.000000  0.778481\n",
    "actual_2     93.000000   88.00000  649.000000  0.781928\n",
    "precision     0.875801    0.76875    0.779112  0.821022\n",
    "======== Random Forest =======\n",
    "                pred_0      pred_1      pred_2    recall\n",
    "actual_0   1148.000000   40.000000   71.000000  0.911835\n",
    "actual_1    108.000000  435.000000   89.000000  0.688291\n",
    "actual_2    192.000000   87.000000  551.000000  0.663855\n",
    "precision     0.792818    0.774021    0.774965  0.784270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params={'task':'train','objective':'multiclass','num_class':3,}\n",
    "\n",
    "# train_set = lgb.Dataset(phrase_train,train.label.values)\n",
    "# model = lgb.train(params=params,train_set=train_set)\n",
    "# val_pred = model.predict(phrase_val)\n",
    "# val_pred = np.argmax(val_pred,axis=1)\n",
    "# evl = eval_mat(val.label.values, val_pred)\n",
    "# print('======== lightgbm =======')\n",
    "# print(evl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
