{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T17:35:04.108156Z",
     "start_time": "2018-07-18T17:35:02.455158Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.801 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import pickle\n",
    "import sys,os\n",
    "import re\n",
    "import jieba\n",
    "jieba.load_userdict(\"../../MLModel/code/WordCut/userdict.txt\")\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T17:35:24.350296Z",
     "start_time": "2018-07-18T17:35:24.284675Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('../../MLModel/code/TimePattern/')\n",
    "from  time_pattern import TimePattern\n",
    "t = TimePattern('../../MLModel/code/TimePattern/mapping.csv')\n",
    "kf = KFold(n_splits=10, shuffle=False, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T17:41:01.116650Z",
     "start_time": "2018-07-18T17:40:54.833600Z"
    }
   },
   "outputs": [],
   "source": [
    "def sub_df(df,sets,target='label'):\n",
    "    result = pd.DataFrame()\n",
    "    for each in sets:\n",
    "        result = pd.concat([result,df[df[target]==each]])\n",
    "#     print(result[target].value_counts())\n",
    "    return result\n",
    "\n",
    "\n",
    "def cut_words(text):\n",
    "    ##### more -- added by wei\n",
    "    # this is used to remove time patterns from sentence\n",
    "    text = re.sub(r' ','',text)\n",
    "    text = t.remove_time(text)\n",
    "    #########\n",
    "    seg_list = jieba.cut(text, cut_all=False)\n",
    "    return \" \".join(seg_list)\n",
    "\n",
    "def clean(text):\n",
    "    text = re.sub(f'([{string.punctuation}“”¨«»®´·º ½¾¿¡§£₤‘’，])',' ', text)\n",
    "    text = text.split(' ')\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "def clean_label(label):\n",
    "    return int(label)\n",
    "\n",
    "others = pd.read_csv('../../MLModel/data/others/irrelevant_response_training_set.csv')\n",
    "other_matrix = pd.read_csv('../../MLModel/data/others/strategy_mat.csv')\n",
    "\n",
    "others = others.rename({'文本':'original_text','类别':'from'},axis=1)\n",
    "mapping = other_matrix.set_index('category').label.drop_duplicates()\n",
    "others['original_label'] = others['from'].map(mapping)\n",
    "\n",
    "others['split_text']=others['original_text'].apply(cut_words)\n",
    "    \n",
    "# # cleaning and save\n",
    "others['split_text'] = others['split_text'].apply(clean)\n",
    "\n",
    "data = others.copy()\n",
    "data = data.sample(frac=1,random_state=19)\n",
    "\n",
    "# K fold\n",
    "kf = KFold(n_splits=10, shuffle=False, random_state=None)\n",
    "ss = kf.split(data)\n",
    "result = pd.DataFrame()\n",
    "\n",
    "all_preds = np.array([])\n",
    "\n",
    "for train_index,val_index in ss:\n",
    "    train_df = data.iloc[train_index]\n",
    "    val_df = data.iloc[val_index].copy()\n",
    "    train_data = train_df.split_text.values\n",
    "    val_data = val_df.split_text.values\n",
    "    phrase_vectorizer = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                strip_accents='unicode', \n",
    "                                max_features=100000, \n",
    "                                analyzer='word',\n",
    "                                sublinear_tf=True,\n",
    "                                token_pattern=r'\\w{1,}')\n",
    "\n",
    "\n",
    "    phrase_vectorizer.fit(train_data)\n",
    "    train_tfidf = phrase_vectorizer.transform(train_data)\n",
    "    val_tfidf = phrase_vectorizer.transform(val_data)\n",
    "    \n",
    "    # linear svc\n",
    "    l_svc = LinearSVC()\n",
    "    lsvc = CalibratedClassifierCV(l_svc) \n",
    "    lsvc.fit(train_tfidf, train_df.original_label)\n",
    "    preds = lsvc.predict(val_tfidf)\n",
    "    val_df['pred_label'] = preds\n",
    "    val_df = val_df[val_df.original_label != val_df.pred_label]\n",
    "    result = pd.concat([result,val_df])\n",
    "    all_preds = np.concatenate([all_preds,preds])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T17:44:33.285727Z",
     "start_time": "2018-07-18T17:44:33.103878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_100</th>\n",
       "      <th>pred_101</th>\n",
       "      <th>pred_102</th>\n",
       "      <th>pred_103</th>\n",
       "      <th>pred_104</th>\n",
       "      <th>pred_105</th>\n",
       "      <th>pred_106</th>\n",
       "      <th>pred_107</th>\n",
       "      <th>pred_108</th>\n",
       "      <th>pred_109</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_100</th>\n",
       "      <td>380.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.785124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_101</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.699219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_102</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.822823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_103</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_104</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.862069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_105</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.838863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_106</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.544601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_107</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.824405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_108</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.827907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_109</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1083.000000</td>\n",
       "      <td>0.787636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.758475</td>\n",
       "      <td>0.813056</td>\n",
       "      <td>0.870253</td>\n",
       "      <td>0.799722</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.782486</td>\n",
       "      <td>0.824074</td>\n",
       "      <td>0.821077</td>\n",
       "      <td>0.807029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pred_100    pred_101    pred_102    pred_103    pred_104  \\\n",
       "actual_100  380.000000    0.000000   20.000000    3.000000   26.000000   \n",
       "actual_101    1.000000  179.000000    3.000000   14.000000    7.000000   \n",
       "actual_102   13.000000    1.000000  274.000000    3.000000    8.000000   \n",
       "actual_103    4.000000    6.000000    2.000000  550.000000   10.000000   \n",
       "actual_104   13.000000    8.000000    3.000000    9.000000  575.000000   \n",
       "actual_105    4.000000    0.000000    3.000000    1.000000   15.000000   \n",
       "actual_106   37.000000    4.000000    7.000000    2.000000    9.000000   \n",
       "actual_107    2.000000    8.000000    5.000000    6.000000    5.000000   \n",
       "actual_108    8.000000    2.000000    1.000000    2.000000    1.000000   \n",
       "actual_109   43.000000   28.000000   19.000000   42.000000   63.000000   \n",
       "precision     0.752475    0.758475    0.813056    0.870253    0.799722   \n",
       "\n",
       "              pred_105    pred_106    pred_107    pred_108     pred_109  \\\n",
       "actual_100    1.000000   21.000000    1.000000    9.000000    23.000000   \n",
       "actual_101    1.000000    3.000000   15.000000    3.000000    30.000000   \n",
       "actual_102    4.000000    4.000000    1.000000    5.000000    20.000000   \n",
       "actual_103    1.000000    0.000000    6.000000    0.000000    26.000000   \n",
       "actual_104    6.000000    3.000000    1.000000    0.000000    49.000000   \n",
       "actual_105  177.000000    0.000000    1.000000    1.000000     9.000000   \n",
       "actual_106    0.000000  116.000000    0.000000    4.000000    34.000000   \n",
       "actual_107    1.000000    1.000000  277.000000    0.000000    31.000000   \n",
       "actual_108    7.000000    0.000000    2.000000  178.000000    14.000000   \n",
       "actual_109    9.000000   22.000000   50.000000   16.000000  1083.000000   \n",
       "precision     0.855072    0.682353    0.782486    0.824074     0.821077   \n",
       "\n",
       "              recall  \n",
       "actual_100  0.785124  \n",
       "actual_101  0.699219  \n",
       "actual_102  0.822823  \n",
       "actual_103  0.909091  \n",
       "actual_104  0.862069  \n",
       "actual_105  0.838863  \n",
       "actual_106  0.544601  \n",
       "actual_107  0.824405  \n",
       "actual_108  0.827907  \n",
       "actual_109  0.787636  \n",
       "precision   0.807029  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('../../Lib/')\n",
    "from model_matrix import eval_mat\n",
    "eval_mat(data.original_label.values,all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T17:51:38.567384Z",
     "start_time": "2018-07-18T17:51:38.546109Z"
    }
   },
   "outputs": [],
   "source": [
    "others = pd.read_csv('../../MLModel/data/others/irrelevant_response_training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T17:52:24.303341Z",
     "start_time": "2018-07-18T17:52:24.294818Z"
    }
   },
   "outputs": [],
   "source": [
    "others = others.sort_values('类别')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T17:52:51.833529Z",
     "start_time": "2018-07-18T17:52:51.820685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "故意岔开话题    1375\n",
       "请求等下打来     667\n",
       "请求重复       605\n",
       "讨价还价       484\n",
       "回问身份       336\n",
       "确认数额       333\n",
       "说出目的       256\n",
       "还款方式       215\n",
       "模糊确认       213\n",
       "其它通讯方式     211\n",
       "Name: 类别, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "others['类别'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T19:41:21.196842Z",
     "start_time": "2018-07-10T19:41:21.187559Z"
    }
   },
   "outputs": [],
   "source": [
    "jn = [104,103,109]\n",
    "ts = [110,100,102,107]\n",
    "wei = set(others.original_label.value_counts().index.values) - set(jn)-set(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T19:44:05.160675Z",
     "start_time": "2018-07-10T19:44:05.036052Z"
    }
   },
   "outputs": [],
   "source": [
    "df_jn = sub_df(others,jn,'original_label')\n",
    "df_jn.to_csv('../../data/others/jiangning_other.csv',index=False,encoding='utf8')\n",
    "df_ts = sub_df(others,ts,'original_label')\n",
    "df_ts.to_csv('../../data/others/tanshu_other.csv',index=False,encoding='utf8')\n",
    "df_wei = sub_df(others,wei,'original_label')\n",
    "df_wei.to_csv('../../data/others/wei_other.csv',index=False,encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T19:10:25.551165Z",
     "start_time": "2018-07-11T19:10:25.507993Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/others/combined_cleaned_others.csv')\n",
    "df_mapping = pd.read_csv('../../data/others/strategy_mat.csv')\n",
    "mapping = df_mapping.set_index('label').category.drop_duplicates()\n",
    "df['from'] = df.original_label.map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T19:11:46.311211Z",
     "start_time": "2018-07-11T19:11:46.305625Z"
    }
   },
   "outputs": [],
   "source": [
    "df.rename({'from':'类别','original_text':'文本'},inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T19:12:15.547203Z",
     "start_time": "2018-07-11T19:12:15.539957Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(['original_label','split_text'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T19:13:11.349456Z",
     "start_time": "2018-07-11T19:13:11.317940Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('../../data/others/irrelevant_response_training_set.csv',index=False,encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
