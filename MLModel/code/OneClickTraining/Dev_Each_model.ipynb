{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T04:15:56.327060Z",
     "start_time": "2018-09-11T04:15:55.997106Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import sys,os\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T04:15:57.661066Z",
     "start_time": "2018-09-11T04:15:57.041859Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "import sys,os\n",
    "# tpattern_path = '../../../classifier/models/time_pattern/'\n",
    "tpattern_path = '../../../classifier/models/time_extractor/'\n",
    "sys.path.append(tpattern_path)\n",
    "from time_pattern import TimePattern\n",
    "\n",
    "\n",
    "env_path = '../../../classifier/env/'\n",
    "sys.path.append(env_path)\n",
    "from env import ENV\n",
    "log_path = '../../../classifier/lib/'\n",
    "sys.path.append(log_path)\n",
    "from log import Logger\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BaseClassifier:\n",
    "    def __init__(self, **model):\n",
    "        \"\"\"\n",
    "        suggested parameters:\n",
    "        svc, logistic, nb, jieba_path,tfidf\n",
    "        \"\"\"\n",
    "        self._load_model(**model)\n",
    "        self.log = None\n",
    "        self.re_time = TimePattern(logAppendName=self.__class__.__name__)\n",
    "        \n",
    "    def warm_up(self):\n",
    "        self.other.classify('')\n",
    "        \n",
    "    def _load_model(self,**model):\n",
    "        self.svc = model.get('svc')\n",
    "        self.logistic = model.get('logistic')\n",
    "        self.nb = model.get('nb')\n",
    "        self.tfidf = model.get('tfidf')\n",
    "        self.other = model.get('other')\n",
    "        self.weights = model.get('weights')\n",
    "        # load jieba\n",
    "        jieba_path = model.get('jieba_path')\n",
    "        if jieba_path is not None:\n",
    "            jieba.load_userdict(jieba_path)\n",
    "            \n",
    "    def _ext_time(self,sentence, lower_bounder='明天下午5点', upper_bounder='1个月'):\n",
    "        \"\"\"\n",
    "        time label 0: extract length is 0\n",
    "        time label 2: extract length is 2\n",
    "        time label 10: extract length is 1, delta time is within the shortest time\n",
    "        time label 11: extract length is 1, delta time is within the middle time\n",
    "        time label 12: extract length is 1, delta time is greater than the longest time\n",
    "        \"\"\"\n",
    "        lower_bounder_hour = self.re_time.process(lower_bounder)[0]['gapH']\n",
    "        upper_bounder_hour = self.re_time.process(upper_bounder)[0]['gapH']\n",
    "        time_extract = self.re_time.process(sentence)\n",
    "        time_label = 0\n",
    "        if len(time_extract) == 0:\n",
    "            time_label = 0\n",
    "            self.log.debug('No time was extracted!')\n",
    "        elif len(time_extract) > 1:\n",
    "            time_label = 2\n",
    "            self.log.debug('More than 2 times were extracted!')\n",
    "        else:\n",
    "            delta = time_extract[0]['gapH']\n",
    "            self.log.debug('Just one time was extracted! And the time delta is {} hours'.format(delta))\n",
    "            if delta < lower_bounder_hour:\n",
    "                time_label = 10\n",
    "                self.log.debug('The delta is less than lower bounder {} hours'.format(lower_bounder_hour))\n",
    "            elif lower_bounder_hour <= delta < upper_bounder_hour:\n",
    "                time_label = 11\n",
    "                self.log.debug('The delta is greater than lower bounder {} hours but less than upper bounder {} hours'.format(lower_bounder_hour,upper_bounder_hour))\n",
    "            else:\n",
    "                time_label = 12\n",
    "                self.log.debug('The delta is greater than upper bounder {} hours'.format(upper_bounder))\n",
    "                \n",
    "        return {'label':time_label,\n",
    "                'time_extract':time_extract,\n",
    "                'lower_bounder_hour':lower_bounder_hour,\n",
    "                'upper_bounder_hour':upper_bounder_hour}\n",
    "    \n",
    "    def preds_ml(self,sentence,removeTime=True):\n",
    "        if self.log is None:\n",
    "            self.log = Logger(self.__class__.__name__,level=ENV.MODEL_LOG_LEVEL.value).logger\n",
    "        if removeTime:\n",
    "            sentence = self.re_time.remove_time(sentence)\n",
    "        sentence = jieba.cut(sentence, cut_all = False)\n",
    "        sentence = ' '.join(sentence)\n",
    "        matrix = self.tfidf.transform([sentence])\n",
    "        self.log.debug('In transfered tfidf, the number of words in vocalbulary is: {}'.format(len(matrix.data)))\n",
    "        result = np.vstack((self.svc.predict_proba(matrix),\n",
    "                                 self.logistic.predict_proba(matrix),\n",
    "                                 self.nb.predict_proba(matrix)))\n",
    "        if self.weights is not None:\n",
    "            if len(self.weights) == result.shape[0]:\n",
    "                av_pred = result[0] * self.weights[0]\n",
    "                for r_idx in range(1,result.shape[0]):\n",
    "                    av_pred += result[r_idx] * self.weights[r_idx]\n",
    "                av_pred = av_pred / sum(self.weights)\n",
    "        else:\n",
    "            av_pred = np.mean(result, axis = 0)\n",
    "        max_pred = np.max(av_pred, axis = 0)\n",
    "        max_arg = np.argmax(av_pred)\n",
    "        response = None\n",
    "        label = max_arg\n",
    "        if label == 2:\n",
    "            response = self.other.classify(sentence)\n",
    "            label = response['label']\n",
    "        return label,result,av_pred,response\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "class IDClassifier(BaseClassifier):\n",
    "    \n",
    "    def __init__(self,**model):\n",
    "        super().__init__(**model)\n",
    "        self.label_meaning = 'ifDebtorAnswersing'\n",
    "        self.label_meaning_map = {0:'y',1:'n'}\n",
    "       \n",
    "    def classify(self, sentence,lower_bounder=None,upper_bounder=None,debug=False):\n",
    "        \"\"\"\n",
    "        ML model wrapper. No time regular expression involved!\n",
    "        input: sentence - type string\n",
    "        return label\n",
    "        \"\"\"\n",
    "        ml_label,result,av_pred,response = self.preds_ml(sentence)\n",
    "        label = ml_label\n",
    "        if debug:\n",
    "            dictionary = {'label': ml_label, 'pred_prob': result,\n",
    "                          'av_pred': av_pred,'other_response':response,'ml_label':ml_label}\n",
    "        else:\n",
    "            if response is not None:\n",
    "                response = float(max(response['av_pred']))\n",
    "            av_pred_value = float(max(av_pred))\n",
    "            dictionary = {'label': label, 'av_pred': av_pred_value,\n",
    "                          'other_response':response,'ml_label':ml_label}\n",
    "        self.log.debug('Final Pred label is: {}'.format(label))\n",
    "        dictionary.update({self.label_meaning:self.label_meaning_map.get(label,'null')})\n",
    "        return dictionary\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class IfKnowDebtor(BaseClassifier):\n",
    "    \n",
    "    def __init__(self,**model):\n",
    "        super().__init__(**model)\n",
    "        self.label_meaning = 'ifKnowDebtor'\n",
    "        self.label_meaning_map = {0:'y',1:'n'}\n",
    "        \n",
    "        \n",
    "    def classify(self, sentence,lower_bounder=None,upper_bounder=None,debug=False):\n",
    "        \"\"\"\n",
    "        ML model wrapper. No time regular expression involved!\n",
    "        input: sentence - type string\n",
    "        return label\n",
    "        \"\"\"\n",
    "        ml_label,result,av_pred,response = self.preds_ml(sentence)\n",
    "        label = ml_label\n",
    "        if debug:\n",
    "            dictionary = {'label': label, 'pred_prob': result,\n",
    "                          'av_pred': av_pred,'other_response':response,'ml_label':ml_label}\n",
    "        else:\n",
    "            if response is not None:\n",
    "                response = float(max(response['av_pred']))\n",
    "            av_pred_value = float(max(av_pred))\n",
    "            dictionary = {'label': label, 'av_pred': av_pred_value,\n",
    "                          'other_response':response,'ml_label':ml_label}\n",
    "        \n",
    "        self.log.debug('Final Pred label is: {}'.format(label))\n",
    "        dictionary.update({self.label_meaning:self.label_meaning_map.get(label,'null')})\n",
    "        return dictionary\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "class ConfirmLoan(BaseClassifier):\n",
    "    \n",
    "    def __init__(self,**model):\n",
    "        super().__init__(**model)\n",
    "        self.label_meaning = 'ifAdmitLoan'\n",
    "        self.label_meaning_map = {0:'y',1:'n'}\n",
    "        \n",
    "    def classify(self, \n",
    "                 sentence,\n",
    "                 lower_bounder='明天下午5点', \n",
    "                 upper_bounder='1个月',debug=False):\n",
    "        \"\"\"\n",
    "        if len(time_extract) == 0 --> run through ML\n",
    "        if len(time_extract) == 1(within short time) --> jump to n103\n",
    "            other --> jump to n15\n",
    "        \"\"\"\n",
    "        ml_label,result,av_pred,response = self.preds_ml(sentence)\n",
    "        label = ml_label\n",
    "     \n",
    "        if debug:\n",
    "            dictionary = {'label': label, 'pred_prob': result, \n",
    "                          'av_pred': av_pred,'other_response':response,'ml_label':ml_label}\n",
    "        else:\n",
    "            if response is not None:\n",
    "                response = float(max(response['av_pred']))\n",
    "            av_pred_value = float(max(av_pred))\n",
    "            dictionary = {'label': label, 'av_pred': av_pred_value,\n",
    "                          'other_response':response,'ml_label':ml_label}\n",
    "        self.log.debug('Final Pred label is: {}'.format(label))\n",
    "        dictionary.update({self.label_meaning:self.label_meaning_map.get(label,'null')})\n",
    "        return dictionary\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "class WillingToPay(BaseClassifier):\n",
    "    def __init__(self,**model):\n",
    "        super().__init__(**model)\n",
    "        self.label_meaning = 'ifWillingToPay'\n",
    "        self.label_meaning_map = {0:'y',1:'n',10:'confirmAgain'}\n",
    "    \n",
    "        \n",
    "        \n",
    "    def classify(self, \n",
    "                 sentence,\n",
    "                 lower_bounder='明天下午5点', \n",
    "                 upper_bounder='1个月',debug=False):\n",
    "        \"\"\"\n",
    "        0 - high willing to pay (ML + Reg, between short and long)\n",
    "        1 - not willing to pay (ML + Reg, too long)\n",
    "        2 - other\n",
    "        Re:\n",
    "        if time len(extract) >=2, and the min time is within the tolerance --> connect to self and confirm which day to pay,\n",
    "                                    output label is 10\n",
    "        if time len(extract) ==1, and the min time is within the tolerance --> run through ML\n",
    "                                    and the min time is within the middle time --> not run ML, connect to self, output label 1,\n",
    "                                    and the min time is longer than the longest time --> no ML, connect to self,output1 sentiment +1\n",
    "        \"\"\"\n",
    "        if self.log is None:\n",
    "            self.log = Logger(self.__class__.__name__,level=ENV.MODEL_LOG_LEVEL.value).logger\n",
    "        dictionary = {}\n",
    "        # Regular expression\n",
    "        time_result = self._ext_time(sentence,lower_bounder, upper_bounder)\n",
    "        time_label = time_result['label']\n",
    "        time_extract = time_result['time_extract']\n",
    "        lower_bounder_hour = time_result['lower_bounder_hour']\n",
    "        upper_bounder_hour = time_result['upper_bounder_hour']\n",
    "        response = None\n",
    "        \n",
    "        ml_label,result,av_pred,response = self.preds_ml(sentence)\n",
    "        label = ml_label\n",
    "        \n",
    "        \n",
    "        if time_label == 2:   \n",
    "            min_time = time_extract[0]['gapH']\n",
    "            for each in time_extract[1:]:\n",
    "                _time = each['gapH']\n",
    "                if _time < min_time:\n",
    "                    min_time = _time      \n",
    "            if min_time <= lower_bounder_hour:\n",
    "                self.log.debug('There are more than 1 time extracted. And the min {} hours is shorter than lower bounder! The output label is set to 10!'.format(min_time))\n",
    "                label = 10\n",
    "            else:\n",
    "                label = 1\n",
    "                \n",
    "            dictionary.update({'label': label, 'av_pred': 1.0,\n",
    "                          'other_response':0.0,'timeExtract':time_extract,'ml_label':ml_label})\n",
    "            dictionary.update({self.label_meaning:self.label_meaning_map.get(label,'null')})\n",
    "            return dictionary\n",
    "        else:    \n",
    "            \n",
    "            # interact with regular expression\n",
    "            if (time_label == 2) and (label != 1):\n",
    "                label = 10\n",
    "            \n",
    "            ####### interact with Regular expression\n",
    "            if time_label == 11:\n",
    "                label = 1\n",
    "            elif time_label == 12:\n",
    "                label = 1\n",
    "                dictionary.update({'add_sentiment':1})\n",
    "            if debug:\n",
    "                dictionary.update({'label': label, 'pred_prob': result, \n",
    "                              'av_pred': av_pred,'other_response':response,'ml_label':ml_label})\n",
    "            else:\n",
    "                if response is not None:\n",
    "                    response = float(max(response['av_pred']))\n",
    "                av_pred_value = float(max(av_pred))\n",
    "                dictionary.update({'label': label, 'av_pred': av_pred_value,\n",
    "                              'other_response':response,'ml_label':ml_label})\n",
    "            dictionary.update({'timeExtract':time_extract})\n",
    "            self.log.debug('Final Pred label is: {}'.format(label))\n",
    "            dictionary.update({self.label_meaning:self.label_meaning_map.get(label,'null')})\n",
    "            return dictionary\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class CutDebt(BaseClassifier):\n",
    "    def __init__(self,**model):\n",
    "        super().__init__(**model)\n",
    "        self.label_meaning = 'ifAcceptCutDebt'\n",
    "        self.label_meaning_map = {0:'y',1:'n'}\n",
    "        \n",
    "    def classify(self, \n",
    "                 sentence,\n",
    "                 lower_bounder='明天下午5点', \n",
    "                 upper_bounder='1个月',debug=False):\n",
    "        \"\"\"\n",
    "        Re:\n",
    "        if time len(extract) >=2, and the min time is within the tolerance --> connect to self and confirm which day to pay,\n",
    "                                    output label is 10\n",
    "        if time len(extract) ==1, and the min time is within the tolerance --> run through ML\n",
    "                                    and the min time is within the middle time --> not run ML, connect to self, output label 1,\n",
    "                                    and the min time is longer than the longest time --> no ML, connect to self,output1 sentiment +1\n",
    "        \"\"\"\n",
    "        if self.log is None:\n",
    "            self.log = Logger(self.__class__.__name__,level=ENV.MODEL_LOG_LEVEL.value).logger\n",
    "        dictionary = {}\n",
    "        # Regular expression\n",
    "        time_result = self._ext_time(sentence,lower_bounder, upper_bounder)\n",
    "        time_label = time_result['label']\n",
    "        time_extract = time_result['time_extract'] \n",
    "        lower_bounder_hour = time_result['lower_bounder_hour']\n",
    "        upper_bounder_hour = time_result['upper_bounder_hour']\n",
    "        response = None\n",
    "        \n",
    "        ml_label,result,av_pred,response = self.preds_ml(sentence)\n",
    "        label = ml_label\n",
    "            \n",
    "        if time_label == 2:   \n",
    "            min_time = time_extract[0]['gapH']\n",
    "            for each in time_extract[1:]:\n",
    "                _time = each['gapH']\n",
    "                if _time < min_time:\n",
    "                    min_time = _time      \n",
    "            if min_time <= lower_bounder_hour:\n",
    "                self.log.debug('There are more than 1 time extracted. And the min {} hours is shorter than lower bounder! The output label is set to 10!'.format(min_time))\n",
    "                label = 10\n",
    "            else:\n",
    "                label = 1\n",
    "                \n",
    "            dictionary = {'label': label, 'av_pred': 1.0,\n",
    "                          'other_response':0.0,'timeExtract':time_extract,'ml_label':ml_label} \n",
    "            dictionary.update({self.label_meaning:self.label_meaning_map.get(label,'null')})\n",
    "            return dictionary\n",
    "        else:\n",
    "\n",
    "            # interact with regular expression\n",
    "            if (time_label == 2) and (label != 1):\n",
    "                label = 10\n",
    "            \n",
    "            ####### interact with Regular expression\n",
    "            if time_label == 11:\n",
    "                label = 1\n",
    "            elif time_label == 12:\n",
    "                dictionary.update({'add_sentiment':1})\n",
    "                label = 1\n",
    "            if debug:\n",
    "                dictionary.update({'label': label, 'pred_prob': result, \n",
    "                              'av_pred': av_pred,'other_response':response,'ml_label':ml_label})\n",
    "            else:\n",
    "                if response is not None:\n",
    "                    response = float(max(response['av_pred']))\n",
    "                av_pred_value = float(max(av_pred))\n",
    "                dictionary.update({'label': label, 'av_pred': av_pred_value,\n",
    "                              'other_response':response,'ml_label':ml_label})\n",
    "            dictionary.update({'timeExtract':time_extract})\n",
    "            self.log.debug('Final Pred label is: {}'.format(label))\n",
    "            dictionary.update({self.label_meaning:self.label_meaning_map.get(label,'null')})\n",
    "            return dictionary\n",
    "    \n",
    "    \n",
    "    \n",
    "class Installment(BaseClassifier):\n",
    "    def __init__(self,**model):\n",
    "        super().__init__(**model)\n",
    "        self.label_meaning = 'ifAcceptInstallment'\n",
    "        self.label_meaning_map = {0:'y',1:'n'}\n",
    "        \n",
    "        \n",
    "    def classify(self, \n",
    "                 sentence,\n",
    "                 lower_bounder='明天下午5点', \n",
    "                 upper_bounder='1个月',debug=False):\n",
    "        \"\"\"\n",
    "        Re:\n",
    "        if time len(extract) >=2, and the min time is within the tolerance --> connect to self and confirm which day to pay,\n",
    "                                    output label is 10\n",
    "        if time len(extract) ==1, and the min time is within the tolerance --> run through ML\n",
    "                                    and the min time is within the middle time --> not run ML, connect to self, output label 1,\n",
    "                                    and the min time is longer than the longest time --> no ML, connect to self,output1 sentiment +1\n",
    "        \"\"\"\n",
    "        if self.log is None:\n",
    "            self.log = Logger(self.__class__.__name__,level=ENV.MODEL_LOG_LEVEL.value).logger\n",
    "        dictionary= {}\n",
    "        # Regular expression\n",
    "        time_result = self._ext_time(sentence,lower_bounder, upper_bounder)\n",
    "        time_label = time_result['label']\n",
    "        time_extract = time_result['time_extract']\n",
    "        lower_bounder_hour = time_result['lower_bounder_hour']\n",
    "        upper_bounder_hour = time_result['upper_bounder_hour']\n",
    "        response = None\n",
    "        \n",
    "        ml_label,result,av_pred,response = self.preds_ml(sentence)\n",
    "        label = ml_label\n",
    "            \n",
    "        if time_label == 2:   \n",
    "            min_time = time_extract[0]['gapH']\n",
    "            for each in time_extract[1:]:\n",
    "                _time = each['gapH']\n",
    "                if _time < min_time:\n",
    "                    min_time = _time      \n",
    "            if min_time <= lower_bounder_hour:\n",
    "                self.log.debug('There are more than 1 time extracted. And the min {} hours is shorter than lower bounder! The output label is set to 10!'.format(min_time))\n",
    "                label = 10\n",
    "            else:\n",
    "                label = 1\n",
    "                \n",
    "            dictionary.update({'label': label, 'av_pred': 1.0,\n",
    "                          'other_response':0.0,'timeExtract':time_extract,'ml_label':ml_label})\n",
    "            dictionary.update({self.label_meaning:self.label_meaning_map.get(label,'null')})\n",
    "            return dictionary\n",
    "        else:\n",
    "\n",
    "            ####### interact with Regular expression\n",
    "            if time_label == 11:\n",
    "                label = 1\n",
    "            elif time_label == 12:\n",
    "                label = 1\n",
    "                dictionary.update({'add_sentiment':1})\n",
    "            if debug:\n",
    "                dictionary.update({'label': label, 'pred_prob': result, \n",
    "                              'av_pred': av_pred,'other_response':response,'ml_label':ml_label})\n",
    "            else:\n",
    "                if response is not None:\n",
    "                    response = float(max(response['av_pred']))\n",
    "                av_pred_value = float(max(av_pred))\n",
    "                dictionary.update({'label': label, 'av_pred': av_pred_value,\n",
    "                              'other_response':response,'ml_label':ml_label})\n",
    "            dictionary.update({'timeExtract':time_extract})\n",
    "            self.log.debug('Final Pred label is: {}'.format(label))\n",
    "            dictionary.update({self.label_meaning:self.label_meaning_map.get(label,'null')})\n",
    "            return dictionary\n",
    "\n",
    "\n",
    "\n",
    "class ClassifierOther:\n",
    "    def __init__(self, **model):\n",
    "        \"\"\"\n",
    "        suggested parameters:\n",
    "        svc, logistic, nb, jieba_path, tfidf\n",
    "        \"\"\"\n",
    "        self.log = None\n",
    "        self._load_model(**model)\n",
    "        self._load_attributes(**model)\n",
    "        \n",
    "        \n",
    "    def _load_model(self,**model):\n",
    "        self.svc = model.get('svc')\n",
    "        self.logistic = model.get('logistic')\n",
    "        self.nb = model.get('nb')\n",
    "        self.tfidf = model.get('tfidf')\n",
    "        self.weights = model.get('weights')\n",
    "        # load jieba\n",
    "        jieba_path = model.get('jieba_path')\n",
    "        if jieba_path is not None:\n",
    "            jieba.load_userdict(jieba_path)\n",
    "        \n",
    "            \n",
    "    def _load_attributes(self, **model):\n",
    "        self.label_mapping = model.get('possible_label')\n",
    "        self.label_mapping = sorted(list(set(self.label_mapping)))\n",
    "        \n",
    "    \n",
    "    def classify(self, sentence):\n",
    "        \"\"\"\n",
    "        input: sentence\n",
    "        output: result(dictionary)\n",
    "        \"\"\"\n",
    "        if self.log is None:\n",
    "            self.log = Logger(self.__class__.__name__,level=ENV.MODEL_LOG_LEVEL.value).logger\n",
    "        sentence = jieba.cut(sentence, cut_all = False)\n",
    "        sentence = ' '.join(sentence)\n",
    "        matrix = self.tfidf.transform([sentence])\n",
    "        self.log.debug('In transfered tfidf, the number of words in vocalbulary is: {}'.format(len(matrix.data)))\n",
    "        \n",
    "        result = np.vstack((self.svc.predict_proba(matrix),\n",
    "                                 self.logistic.predict_proba(matrix),\n",
    "                                 self.nb.predict_proba(matrix))) \n",
    "        \n",
    "        if self.weights is not None:\n",
    "            if len(self.weights) == result.shape[0]:\n",
    "                av_pred = result[0] * self.weights[0]\n",
    "                for r_idx in range(1,result.shape[0]):\n",
    "                    av_pred += result[r_idx] * self.weights[r_idx]\n",
    "                av_pred = av_pred / sum(self.weights)\n",
    "        else:\n",
    "            av_pred = np.mean(result, axis = 0)\n",
    "        \n",
    "        av_pred = np.mean(result, axis = 0)\n",
    "        max_pred = np.max(av_pred, axis = 0)\n",
    "        max_arg = np.argmax(av_pred)\n",
    "        \n",
    "        label = max_arg\n",
    "        label = self.label_mapping[label]\n",
    "            \n",
    "        dictionary = {'label': label, 'pred_prob': result, 'av_pred': av_pred}\n",
    "        self.log.debug('Possible labels are: {}'.format(self.label_mapping))\n",
    "        self.log.debug('Other- Final Pred label is: {}'.format(dictionary['label']))\n",
    "        self.log.debug('Other- svc,logistic,nb result:\\n {}'.format(dictionary['pred_prob']))\n",
    "        self.log.debug('Other- ave result:\\n {}'.format(dictionary['av_pred']))\n",
    "        return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T04:15:57.750443Z",
     "start_time": "2018-09-11T04:15:57.740488Z"
    }
   },
   "outputs": [],
   "source": [
    "model_list = {\n",
    "                'IDClassifier':IDClassifier, \n",
    "                  'CutDebt':CutDebt, \n",
    "                  'WillingToPay':WillingToPay,\n",
    "                  'IfKnowDebtor':IfKnowDebtor,\n",
    "                  'Installment':Installment,\n",
    "                  'ConfirmLoan':ConfirmLoan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T04:15:59.325867Z",
     "start_time": "2018-09-11T04:15:58.473799Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.830 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "import jieba\n",
    "jieba.load_userdict(\"../../code/WordCut/userdict.txt\")\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T04:31:57.744378Z",
     "start_time": "2018-09-11T04:31:57.728995Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_other_model(other_data,save_path,model):\n",
    "    phrase_vectorizer_other = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                strip_accents='unicode', \n",
    "                                max_features=100000, \n",
    "                                analyzer='word',\n",
    "                                sublinear_tf=True,\n",
    "                                token_pattern=r'\\w{1,}')\n",
    "\n",
    "    print('fitting phrase')\n",
    "    phrase_vectorizer_other.fit(other_data.text)\n",
    "\n",
    "    print('transform phrase')\n",
    "    phrase = phrase_vectorizer_other.transform(other_data.text)\n",
    "\n",
    "\n",
    "    # linear svc\n",
    "    l_svc = LinearSVC()\n",
    "    lsvc = CalibratedClassifierCV(l_svc) \n",
    "    lsvc.fit(phrase, other_data.label)\n",
    "\n",
    "\n",
    "    # logistic\n",
    "    log_r = LogisticRegression()\n",
    "    log_r.fit(phrase, other_data.label)\n",
    "\n",
    "\n",
    "    # Naive Bayes\n",
    "    naive_b = MultinomialNB()\n",
    "    naive_b.fit(phrase, other_data.label)\n",
    "    \n",
    "    print('finish training others')\n",
    "    \n",
    "    \n",
    "    # other wrapper \n",
    "    other_model = ClassifierOther(svc=lsvc, logistic=log_r, nb=naive_b, tfidf=phrase_vectorizer_other, jieba_path='../WordCut/userdict.txt',possible_label=lsvc.classes_)\n",
    "    \n",
    "    return other_model\n",
    "    \n",
    "    \n",
    "def train_main_model(df,save_path,model,other_model):\n",
    "    # get tfidf\n",
    "    \n",
    "    phrase_vectorizer = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                    strip_accents='unicode', \n",
    "                                    max_features=100000, \n",
    "                                    analyzer='word',\n",
    "                                    sublinear_tf=True,\n",
    "                                    token_pattern=r'\\w{1,}')\n",
    "    \n",
    "\n",
    "    print('fitting phrase')\n",
    "    phrase_vectorizer.fit(df.split_text)\n",
    "\n",
    "    print('transform phrase')\n",
    "    phrase = phrase_vectorizer.transform(df.split_text)\n",
    "    \n",
    "    # linear svc\n",
    "    l_svc = LinearSVC()\n",
    "    lsvc = CalibratedClassifierCV(l_svc) \n",
    "    lsvc.fit(phrase, df.label)\n",
    "    \n",
    "    \n",
    "    # logistic\n",
    "    log_r = LogisticRegression()\n",
    "    log_r.fit(phrase, df.label)\n",
    "    \n",
    "    \n",
    "    # Naive Bayes\n",
    "    naive_b = MultinomialNB()\n",
    "    naive_b.fit(phrase, df.label)\n",
    "    print('finish training')\n",
    "    \n",
    "    main_model = model_list[model](svc=lsvc, logistic=log_r, nb=naive_b, tfidf=phrase_vectorizer, other=other_model,  jieba_path='../WordCut/userdict.txt',weights=[5,1,1])\n",
    "\n",
    "    return main_model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T04:32:02.969587Z",
     "start_time": "2018-09-11T04:31:58.787686Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 46.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutDebt\n",
      "finish cutting words\n",
      "1    1434\n",
      "0    1364\n",
      "Name: label, dtype: int64\n",
      "109    1376\n",
      "106     997\n",
      "104     907\n",
      "103     552\n",
      "108     355\n",
      "102     266\n",
      "107     133\n",
      "110      33\n",
      "Name: label, dtype: int64\n",
      "IDClassifier\n",
      "finish cutting words\n",
      "1    533\n",
      "0    339\n",
      "Name: label, dtype: int64\n",
      "109    1397\n",
      "104     952\n",
      "103     563\n",
      "107     366\n",
      "Name: label, dtype: int64\n",
      "IfKnowDebtor\n",
      "finish cutting words\n",
      "0    894\n",
      "1    519\n",
      "Name: label, dtype: int64\n",
      "109    1393\n",
      "104     952\n",
      "103     563\n",
      "107     365\n",
      "Name: label, dtype: int64\n",
      "Installment\n",
      "finish cutting words\n",
      "1    1368\n",
      "0    1364\n",
      "Name: label, dtype: int64\n",
      "109    1376\n",
      "106     998\n",
      "104     907\n",
      "103     553\n",
      "108     355\n",
      "102     277\n",
      "107     133\n",
      "110      33\n",
      "Name: label, dtype: int64\n",
      "WillingToPay\n",
      "finish cutting words\n",
      "1    1947\n",
      "0     669\n",
      "Name: label, dtype: int64\n",
      "109    1375\n",
      "106     988\n",
      "104     905\n",
      "103     551\n",
      "108     351\n",
      "102     334\n",
      "105     202\n",
      "107     133\n",
      "Name: label, dtype: int64\n",
      "ConfirmLoan\n",
      "finish cutting words\n",
      "0    1157\n",
      "1     609\n",
      "Name: label, dtype: int64\n",
      "109    1375\n",
      "104     900\n",
      "103     547\n",
      "108     344\n",
      "107     134\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "sys.path.append('../../../Lib/')\n",
    "from load_cleaned_data import load_data\n",
    "clean_data_main,clean_data_other = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Other Model + Main Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train IDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T04:32:04.232401Z",
     "start_time": "2018-09-11T04:32:03.371020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting phrase\n",
      "transform phrase\n",
      "finish training others\n",
      "=====  IDClassifier =======\n",
      "2    3278\n",
      "1     533\n",
      "0     339\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# each_model = 'IDClassifier' \n",
    "save_path_other = ''\n",
    "save_path_main = ''\n",
    "\n",
    "each_model = 'IDClassifier'\n",
    "other_model = train_other_model(clean_data_other[each_model],save_path_other,each_model)\n",
    "    \n",
    "df_main = clean_data_main[each_model].copy()\n",
    "other_label = int(max(set(df_main.label)) + 1)\n",
    "ava_others = clean_data_other[each_model].rename({'text':'split_text'},axis=1).copy()\n",
    "ava_others['label'] = other_label\n",
    "df_main = pd.concat([df_main,ava_others],sort=True)\n",
    "df_main = df_main.sample(frac=1,random_state=6).reset_index(drop=True)\n",
    "print('=====  {} ======='.format(each_model))\n",
    "print(df_main.label.value_counts())\n",
    "clf = train_main_model(df_main,save_path_main,each_model,other_model)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T04:32:04.777619Z",
     "start_time": "2018-09-11T04:32:04.760758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>split_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>你们 通过 什么 渠道 知道 我 的 电话   是 谁 卖 给 你们 的 ？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>我 不想 说</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>打 豆豆 了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>我 在 开会   等 下 再说 吧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>韩国 赢 了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>我 在</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>光脚 的 不怕 穿鞋 的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>他 因为 欠钱 躲起来 了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>你 说 什么 我 在 地铁 里</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>唉 是 的 是 的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>凭 什么 回答 你</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>我 是 他 二 大爷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>我 在 高速 上   等 会 说</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>看清楚 再 打 嘛 哈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>我 这里 太吵 了   听 不 清楚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>你 哪位 ？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>我 在 忙   过会 联系</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>你 不 晓得 老子 是 谁给我 打 什么 电话</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>怎么 了 啊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>TIMEPATTERN 联系</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>你 多 大 了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>啊 ？ 请 用 标准 普通话   不会 说 就 别 打</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>不要 打电话 了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>你 是 谁 ？ 你 为什么 有 我 的 电话 ？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>是不是 和 你 有 关系 吗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>信号 不好 听不见 挂 电话</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>你 在 哪</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>我 在 忙   稍后 回 电话</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>下班 联系</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>我 在 开车   等 会 再说 吧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120</th>\n",
       "      <td>2</td>\n",
       "      <td>开车 呢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>2</td>\n",
       "      <td>说 什么 东西</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>2</td>\n",
       "      <td>喂 … …</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>2</td>\n",
       "      <td>你 是 个 瓜 娃子 哦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>2</td>\n",
       "      <td>自己 去查</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>2</td>\n",
       "      <td>我 这 显示 你 这个 号码 是 推销 号码 喃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>2</td>\n",
       "      <td>要 不 你 等 会 再 打   我 现在 有事</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>2</td>\n",
       "      <td>啊 ？ 俺 听 不到</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>2</td>\n",
       "      <td>你 那边 是不是 信号 不好</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4129</th>\n",
       "      <td>2</td>\n",
       "      <td>啥 名字</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>2</td>\n",
       "      <td>你 纳闷 晓得 我 电话 啊 ？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>2</td>\n",
       "      <td>大声 TIMEPATTERN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>2</td>\n",
       "      <td>父母 的 干劲儿 会 TIMEPATTERN 更 比 TIMEPATTERN 大</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>2</td>\n",
       "      <td>你们 TIMEPATTERN 工作 好多 小时</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>2</td>\n",
       "      <td>胳膊 太 大   听不清</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>2</td>\n",
       "      <td>有事 就 说   没意思</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>2</td>\n",
       "      <td>我 认识 你 吗 ？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4137</th>\n",
       "      <td>2</td>\n",
       "      <td>我 在 外面   回去 给 你 打 过来 哈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>2</td>\n",
       "      <td>给 你 发点 红包</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4139</th>\n",
       "      <td>2</td>\n",
       "      <td>去 你 的 滚 你 谁 啊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4140</th>\n",
       "      <td>2</td>\n",
       "      <td>太吵 了   说 大声 点</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4141</th>\n",
       "      <td>2</td>\n",
       "      <td>有 时间 再 联系 吧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4142</th>\n",
       "      <td>2</td>\n",
       "      <td>等 我 TIMEPATTERN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4143</th>\n",
       "      <td>2</td>\n",
       "      <td>我 在 开会 等等 再 打来</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>2</td>\n",
       "      <td>我 现在 上班   忙</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>0</td>\n",
       "      <td>喂   啊   我 是   什么 事</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>1</td>\n",
       "      <td>我 刚办 的 卡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>2</td>\n",
       "      <td>现在 不 方便 一会 再说</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>1</td>\n",
       "      <td>不是 不是 挂机</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>2</td>\n",
       "      <td>我 在 睡觉 太累 了</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                split_text\n",
       "0         2    你们 通过 什么 渠道 知道 我 的 电话   是 谁 卖 给 你们 的 ？\n",
       "1         2                                    我 不想 说\n",
       "2         2                                    打 豆豆 了\n",
       "3         2                         我 在 开会   等 下 再说 吧\n",
       "4         2                                    韩国 赢 了\n",
       "5         0                                       我 在\n",
       "6         2                              光脚 的 不怕 穿鞋 的\n",
       "7         1                             他 因为 欠钱 躲起来 了\n",
       "8         2                           你 说 什么 我 在 地铁 里\n",
       "9         0                                 唉 是 的 是 的\n",
       "10        2                                 凭 什么 回答 你\n",
       "11        2                                我 是 他 二 大爷\n",
       "12        2                          我 在 高速 上   等 会 说\n",
       "13        1                               看清楚 再 打 嘛 哈\n",
       "14        2                        我 这里 太吵 了   听 不 清楚\n",
       "15        2                                    你 哪位 ？\n",
       "16        2                             我 在 忙   过会 联系\n",
       "17        2                   你 不 晓得 老子 是 谁给我 打 什么 电话\n",
       "18        2                                    怎么 了 啊\n",
       "19        2                            TIMEPATTERN 联系\n",
       "20        2                                   你 多 大 了\n",
       "21        2               啊 ？ 请 用 标准 普通话   不会 说 就 别 打\n",
       "22        2                                  不要 打电话 了\n",
       "23        2                  你 是 谁 ？ 你 为什么 有 我 的 电话 ？\n",
       "24        2                            是不是 和 你 有 关系 吗\n",
       "25        2                            信号 不好 听不见 挂 电话\n",
       "26        2                                     你 在 哪\n",
       "27        2                           我 在 忙   稍后 回 电话\n",
       "28        2                                     下班 联系\n",
       "29        2                         我 在 开车   等 会 再说 吧\n",
       "...     ...                                       ...\n",
       "4120      2                                      开车 呢\n",
       "4121      2                                   说 什么 东西\n",
       "4122      2                                     喂 … …\n",
       "4123      2                              你 是 个 瓜 娃子 哦\n",
       "4124      2                                     自己 去查\n",
       "4125      2                  我 这 显示 你 这个 号码 是 推销 号码 喃\n",
       "4126      2                   要 不 你 等 会 再 打   我 现在 有事\n",
       "4127      2                                啊 ？ 俺 听 不到\n",
       "4128      2                            你 那边 是不是 信号 不好\n",
       "4129      2                                      啥 名字\n",
       "4130      2                          你 纳闷 晓得 我 电话 啊 ？\n",
       "4131      2                            大声 TIMEPATTERN\n",
       "4132      2  父母 的 干劲儿 会 TIMEPATTERN 更 比 TIMEPATTERN 大\n",
       "4133      2                   你们 TIMEPATTERN 工作 好多 小时\n",
       "4134      2                              胳膊 太 大   听不清\n",
       "4135      2                              有事 就 说   没意思\n",
       "4136      2                                我 认识 你 吗 ？\n",
       "4137      2                    我 在 外面   回去 给 你 打 过来 哈\n",
       "4138      2                                 给 你 发点 红包\n",
       "4139      2                             去 你 的 滚 你 谁 啊\n",
       "4140      2                             太吵 了   说 大声 点\n",
       "4141      2                               有 时间 再 联系 吧\n",
       "4142      2                           等 我 TIMEPATTERN\n",
       "4143      2                            我 在 开会 等等 再 打来\n",
       "4144      2                               我 现在 上班   忙\n",
       "4145      0                        喂   啊   我 是   什么 事\n",
       "4146      1                                  我 刚办 的 卡\n",
       "4147      2                             现在 不 方便 一会 再说\n",
       "4148      1                                  不是 不是 挂机\n",
       "4149      2                               我 在 睡觉 太累 了\n",
       "\n",
       "[4150 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T04:32:24.324589Z",
     "start_time": "2018-09-11T04:32:24.308683Z"
    }
   },
   "outputs": [],
   "source": [
    "for each in clf.tfidf.vocabulary_:\n",
    "    if each.find('？')!=-1:\n",
    "        print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T02:57:21.241705Z",
     "start_time": "2018-09-11T02:57:21.211004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'av_pred': 0.8820170025103654,\n",
       " 'other_response': None,\n",
       " 'ml_label': 0,\n",
       " 'ifDebtorAnswersing': 'y'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classify('是的')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T20:30:14.077391Z",
     "start_time": "2018-09-10T20:30:14.045526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.85350024e-01 1.46383107e-02 1.16649597e-05]\n",
      " [8.76255068e-01 1.05124307e-01 1.86206254e-02]\n",
      " [3.79243623e-01 4.77753862e-02 5.72980991e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'av_pred': 0.7469495714705526,\n",
       " 'other_response': None,\n",
       " 'ml_label': 0,\n",
       " 'ifDebtorAnswersing': 'y'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classify('是的')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Confirm Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T02:57:25.770503Z",
     "start_time": "2018-09-11T02:57:24.116361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting phrase\n",
      "transform phrase\n",
      "finish training others\n",
      "saving to path: \n",
      "=====  ConfirmLoan =======\n",
      "2    3300\n",
      "0    1157\n",
      "1     609\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "saving to path: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# each_model = 'IDClassifier' \n",
    "save_path_other = ''\n",
    "save_path_main = ''\n",
    "\n",
    "each_model = 'ConfirmLoan'\n",
    "other_model = train_other_model(clean_data_other[each_model],save_path_other,each_model)\n",
    "    \n",
    "df_main = clean_data_main[each_model].copy()\n",
    "other_label = int(max(set(df_main.label)) + 1)\n",
    "ava_others = clean_data_other[each_model].rename({'text':'split_text'},axis=1).copy()\n",
    "ava_others['label'] = other_label\n",
    "df_main = pd.concat([df_main,ava_others],sort=True)\n",
    "df_main = df_main.sample(frac=1,random_state=6).reset_index(drop=True)\n",
    "print('=====  {} ======='.format(each_model))\n",
    "print(df_main.label.value_counts())\n",
    "clf = train_main_model(df_main,save_path_main,each_model,other_model)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T02:57:39.295033Z",
     "start_time": "2018-09-11T02:57:38.924926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time_extract' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-15d18b688115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'没钱'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-e9675d442b98>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self, sentence, lower_bounder, upper_bounder, debug)\u001b[0m\n\u001b[1;32m    206\u001b[0m             dictionary = {'label': label, 'av_pred': av_pred_value,\n\u001b[1;32m    207\u001b[0m                           'other_response':response,'ml_label':ml_label}\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'timeExtract'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtime_extract\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Final Pred label is: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_meaning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_meaning_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'null'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time_extract' is not defined"
     ]
    }
   ],
   "source": [
    "clf.classify('没钱')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train WilingToPay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T19:51:39.220632Z",
     "start_time": "2018-09-10T19:51:36.772523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting phrase\n",
      "transform phrase\n",
      "finish training others\n",
      "saving to path: \n",
      "=====  WillingToPay =======\n",
      "2    4839\n",
      "1    1947\n",
      "0     669\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "saving to path: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# each_model = 'IDClassifier' \n",
    "save_path_other = ''\n",
    "save_path_main = ''\n",
    "\n",
    "each_model = 'WillingToPay'\n",
    "other_model = train_other_model(clean_data_other[each_model],save_path_other,each_model)\n",
    "    \n",
    "df_main = clean_data_main[each_model].copy()\n",
    "other_label = int(max(set(df_main.label)) + 1)\n",
    "ava_others = clean_data_other[each_model].rename({'text':'split_text'},axis=1).copy()\n",
    "ava_others['label'] = other_label\n",
    "df_main = pd.concat([df_main,ava_others],sort=True)\n",
    "df_main = df_main.sample(frac=1,random_state=6).reset_index(drop=True)\n",
    "print('=====  {} ======='.format(each_model))\n",
    "print(df_main.label.value_counts())\n",
    "clf = train_main_model(df_main,save_path_main,each_model,other_model)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T19:51:40.533148Z",
     "start_time": "2018-09-10T19:51:40.489313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 19:51:40,491 - INFO - CLASS:EvlTimeExpEngineWillingToPay- METHOD:_set_timeZone -LINE:748 - MSG:Time Zone is set from ENV: Asia/Shanghai. Classifier: WillingToPay\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 10,\n",
       " 'av_pred': 1.0,\n",
       " 'other_response': 0.0,\n",
       " 'timeExtract': [{'pattern': '过58分钟',\n",
       "   'time': datetime.datetime(2018, 9, 11, 4, 49, tzinfo=<DstTzInfo 'Asia/Shanghai' CST+8:00:00 STD>),\n",
       "   'gapS': 3439.473664,\n",
       "   'gapH': 0.9554093511111111,\n",
       "   'gapD': 0.039808722962962964,\n",
       "   'exp': '?y-?m-?d-?H:+58M:00S'},\n",
       "  {'pattern': '明年',\n",
       "   'time': datetime.datetime(2019, 9, 11, 3, 51, tzinfo=<DstTzInfo 'Asia/Shanghai' CST+8:00:00 STD>),\n",
       "   'gapS': 31535959.473581,\n",
       "   'gapH': 8759.98874266139,\n",
       "   'gapD': 364.99953094422455,\n",
       "   'exp': '^1y-?m-?d-?H:?M:00S'}],\n",
       " 'ml_label': 1,\n",
       " 'ifWillingToPay': 'confirmAgain'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classify('过58分钟可以明年不行',lower_bounder='明天下午5点')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:09:55.386432Z",
     "start_time": "2018-09-04T15:09:55.373346Z"
    }
   },
   "source": [
    "# Installment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T19:51:44.255439Z",
     "start_time": "2018-09-10T19:51:41.689957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting phrase\n",
      "transform phrase\n",
      "finish training others\n",
      "saving to path: \n",
      "=====  Installment =======\n",
      "2    4632\n",
      "1    1368\n",
      "0    1364\n",
      "Name: label, dtype: int64\n",
      "fitting phrase\n",
      "transform phrase\n",
      "finish training\n",
      "saving to path: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# each_model = 'IDClassifier' \n",
    "save_path_other = ''\n",
    "save_path_main = ''\n",
    "\n",
    "each_model = 'Installment'\n",
    "other_model = train_other_model(clean_data_other[each_model],save_path_other,each_model)\n",
    "    \n",
    "df_main = clean_data_main[each_model].copy()\n",
    "other_label = int(max(set(df_main.label)) + 1)\n",
    "ava_others = clean_data_other[each_model].rename({'text':'split_text'},axis=1).copy()\n",
    "ava_others['label'] = other_label\n",
    "df_main = pd.concat([df_main,ava_others],sort=True)\n",
    "df_main = df_main.sample(frac=1,random_state=6).reset_index(drop=True)\n",
    "print('=====  {} ======='.format(each_model))\n",
    "print(df_main.label.value_counts())\n",
    "clf = train_main_model(df_main,save_path_main,each_model,other_model)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T19:51:45.698867Z",
     "start_time": "2018-09-10T19:51:45.679027Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 19:51:45,681 - INFO - CLASS:EvlTimeExpEngineInstallment- METHOD:_set_timeZone -LINE:748 - MSG:Time Zone is set from ENV: Asia/Shanghai. Classifier: Installment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 10,\n",
       " 'av_pred': 1.0,\n",
       " 'other_response': 0.0,\n",
       " 'timeExtract': [{'pattern': '过58分钟',\n",
       "   'time': datetime.datetime(2018, 9, 11, 4, 49, tzinfo=<DstTzInfo 'Asia/Shanghai' CST+8:00:00 STD>),\n",
       "   'gapS': 3434.315476,\n",
       "   'gapH': 0.9539765211111112,\n",
       "   'gapD': 0.03974902171296297,\n",
       "   'exp': '?y-?m-?d-?H:+58M:00S'},\n",
       "  {'pattern': '明年',\n",
       "   'time': datetime.datetime(2019, 9, 11, 3, 51, tzinfo=<DstTzInfo 'Asia/Shanghai' CST+8:00:00 STD>),\n",
       "   'gapS': 31535954.315328,\n",
       "   'gapH': 8759.987309813332,\n",
       "   'gapD': 364.99947124222217,\n",
       "   'exp': '^1y-?m-?d-?H:?M:00S'}],\n",
       " 'ml_label': 1,\n",
       " 'ifAcceptInstallment': 'null'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classify('过58分钟可以明年不行',lower_bounder='明天下午5点')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T04:27:19.127278Z",
     "start_time": "2018-09-11T04:27:19.119258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我', '是', '他', '朋友', '？']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "token_pattern=r'\\w{1,}|，|。|？'\n",
    "re.findall(token_pattern,'我 是 他 朋友 ？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
