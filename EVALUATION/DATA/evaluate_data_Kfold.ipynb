{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T15:17:48.689009Z",
     "start_time": "2018-07-19T15:17:48.673445Z"
    }
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import pickle\n",
    "import sys,os\n",
    "sys.path.append('../../MLModel/code/OneClickTraining/')\n",
    "from all_model_py import CutDebt, IDClassifier, IfKnowDebtor, Installment, WillingToPay, ConfirmLoan\n",
    "import re\n",
    "import jieba\n",
    "jieba.load_userdict(\"../../MLModel/code/WordCut/userdict.txt\")\n",
    "import string\n",
    "sys.path.append('../../Lib/')\n",
    "from SUPPORT import balance_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T15:21:30.296542Z",
     "start_time": "2018-07-19T15:20:53.101542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutDebt\n",
      "CutDebt: other label is: 2\n",
      "2    5803\n",
      "0    3623\n",
      "1    2327\n",
      "Name: label, dtype: int64\n",
      "total length is 11753!! Label needs to be checked length is 1680\n",
      "================================\n",
      "IDClassifier\n",
      "IDClassifier: other label is: 2\n",
      "2    4351\n",
      "1    1234\n",
      "0    1133\n",
      "Name: label, dtype: int64\n",
      "total length is 6718!! Label needs to be checked length is 748\n",
      "================================\n",
      "IfKnowDebtor\n",
      "IfKnowDebtor: other label is: 2\n",
      "2    4351\n",
      "0    1363\n",
      "1    1184\n",
      "Name: label, dtype: int64\n",
      "total length is 6898!! Label needs to be checked length is 655\n",
      "================================\n",
      "Installment\n",
      "Installment: other label is: 2\n",
      "2    5803\n",
      "0    3623\n",
      "1    2379\n",
      "Name: label, dtype: int64\n",
      "total length is 11805!! Label needs to be checked length is 1878\n",
      "================================\n",
      "ConfirmLoan\n",
      "ConfirmLoan: other label is: 2\n",
      "2    4280\n",
      "0     713\n",
      "1     548\n",
      "Name: label, dtype: int64\n",
      "total length is 5541!! Label needs to be checked length is 453\n",
      "================================\n",
      "WillingToPay\n",
      "WillingToPay: other label is: 3\n",
      "3    5464\n",
      "1    2620\n",
      "0    1778\n",
      "2    1038\n",
      "Name: label, dtype: int64\n",
      "total length is 10900!! Label needs to be checked length is 1680\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('../../MLModel/code/TimePattern/')\n",
    "from  time_pattern import TimePattern\n",
    "t = TimePattern('../../MLModel/code/TimePattern/mapping.csv')\n",
    "kf = KFold(n_splits=10, shuffle=False, random_state=None)\n",
    "\n",
    "\n",
    "def sub_df(df,sets,target='label'):\n",
    "    result = pd.DataFrame()\n",
    "    for each in sets:\n",
    "        result = pd.concat([result,df[df[target]==each]])\n",
    "#     print(result[target].value_counts())\n",
    "    return result\n",
    "\n",
    "\n",
    "def cut_words(text):\n",
    "    ##### more -- added by wei\n",
    "    # this is used to remove time patterns from sentence\n",
    "    text = re.sub(r' ','',text)\n",
    "    text = t.remove_time(text)\n",
    "    #########\n",
    "    seg_list = jieba.cut(text, cut_all=False)\n",
    "    return \" \".join(seg_list)\n",
    "\n",
    "def clean(text):\n",
    "    text = re.sub(f'([{string.punctuation}“”¨«»®´·º ½¾¿¡§£₤‘’，])',' ', text)\n",
    "    text = text.split(' ')\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "def clean_label(label):\n",
    "    return int(label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "others = pd.read_csv('../../MLModel/data/others/irrelevant_response_training_set.csv')\n",
    "other_matrix = pd.read_csv('../../MLModel/data/others/strategy_mat.csv')\n",
    "\n",
    "others = others.rename({'文本':'original_text','类别':'from'},axis=1)\n",
    "mapping = other_matrix.set_index('category').label.drop_duplicates()\n",
    "others['original_label'] = others['from'].map(mapping)\n",
    "\n",
    "others['split_text']=others['original_text'].apply(cut_words)\n",
    "    \n",
    "# cleaning and save\n",
    "others['split_text'] = others['split_text'].apply(clean)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_list = {'CutDebt':CutDebt,\n",
    "              'IDClassifier':IDClassifier,\n",
    "              'IfKnowDebtor':IfKnowDebtor,\n",
    "              'Installment':Installment,\n",
    "              'ConfirmLoan':ConfirmLoan,\n",
    "              'WillingToPay':WillingToPay}\n",
    "\n",
    "target='label'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for each_model in model_list:\n",
    "    path = '../../MLModel/data/{}/'\n",
    "    data = pd.read_csv(path.format(each_model) + 'mock_up_data1.csv', encoding='utf8')\n",
    "    data['from'] = each_model\n",
    "    data.to_csv(path.format(each_model) + 'combined_mock_up_data_eval.csv', index = False, encoding = 'utf8')\n",
    "    \n",
    "    \n",
    "\n",
    "# label 0 part for CutDebt and Installment\n",
    "data_cut = pd.read_csv(path.format('CutDebt') + 'combined_mock_up_data_eval.csv', encoding = 'utf8')\n",
    "data_ins = pd.read_csv(path.format('Installment') + 'combined_mock_up_data_eval.csv', encoding = 'utf8')\n",
    "temp_cut = data_cut[data_cut.label == 0]\n",
    "temp_ins = data_ins[data_ins.label == 0]\n",
    "data_cut = pd.concat([data_cut,temp_ins], ignore_index=True)\n",
    "data_ins = pd.concat([data_ins,temp_cut], ignore_index=True)\n",
    "data_cut.to_csv(path.format('CutDebt') + 'combined_mock_up_data_eval.csv', index = False, encoding = 'utf8')\n",
    "data_ins.to_csv(path.format('Installment') + 'combined_mock_up_data_eval.csv', index = False, encoding = 'utf8')\n",
    "\n",
    "\n",
    "\n",
    "for each_model in model_list:\n",
    "    print(each_model)\n",
    "    path = '../../MLModel/data/{}/'\n",
    "    data = pd.read_csv(path.format(each_model) + 'combined_mock_up_data_eval.csv', encoding = 'utf8')\n",
    "    data = data.dropna()\n",
    "    col = 'split_text'\n",
    "    \n",
    "    # cut words\n",
    "    data['original_text'] = data['split_text']\n",
    "    data['split_text']=data['split_text'].apply(cut_words)\n",
    "    \n",
    "    # cleaning and save\n",
    "    data['split_text'] = data['split_text'].apply(clean)\n",
    "    data['label'] = data['label'].apply(clean_label)\n",
    "\n",
    "    # shuffle data\n",
    "    data = data.sample(frac=1,random_state=35).reset_index(drop=True)\n",
    "    other_label = int(max(set(data.label)) + 1)\n",
    "    print('{}: other label is: {}'.format(each_model,other_label))\n",
    "    \n",
    "    \n",
    "    other_set = set(other_matrix[other_matrix[each_model]==0].label.values)\n",
    "    ava_others = sub_df(others,other_set,target='original_label')\n",
    "    ava_others[target] = other_label\n",
    "    data = pd.concat([data,ava_others],sort=True)\n",
    "    data = data.sample(frac=1,random_state=21).reset_index(drop=True)\n",
    "    print(data.label.value_counts())\n",
    "    \n",
    "    # prepare data done!\n",
    "    ##################################################################################\n",
    "    # K fold\n",
    "    kf = KFold(n_splits=10, shuffle=False, random_state=None)\n",
    "    ss = kf.split(data)\n",
    "    result = pd.DataFrame()\n",
    "    counter = 0\n",
    "    for train_index,val_index in ss:\n",
    "        train_df = data.iloc[train_index].copy()\n",
    "#         train_df = balance_category(train_df,target='label')\n",
    "        val_df = data.iloc[val_index].copy()\n",
    "        train_data = train_df.split_text.values\n",
    "        val_data = val_df.split_text.values\n",
    "        phrase_vectorizer = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                    strip_accents='unicode', \n",
    "                                    max_features=100000, \n",
    "                                    analyzer='word',\n",
    "                                    sublinear_tf=True,\n",
    "                                    token_pattern=r'\\w{1,}')\n",
    "\n",
    "\n",
    "        phrase_vectorizer.fit(train_data)\n",
    "        train_tfidf = phrase_vectorizer.transform(train_data)\n",
    "        val_tfidf = phrase_vectorizer.transform(val_data)\n",
    "        \n",
    "        # linear svc\n",
    "        l_svc = LinearSVC()\n",
    "        lsvc = CalibratedClassifierCV(l_svc) \n",
    "        lsvc.fit(train_tfidf, train_df.label)\n",
    "        preds = lsvc.predict(val_tfidf)\n",
    "        val_df['pred_label'] = preds\n",
    "        val_df = val_df[val_df.label != val_df.pred_label]\n",
    "        result = pd.concat([result,val_df])\n",
    "    print('total length is {}!! Label needs to be checked length is {}'.format(len(data), len(result)))\n",
    "    print('================================')\n",
    "    result.drop(['pred_label','split_text'],inplace=True, axis=1)\n",
    "    result.to_csv('../../MLModel/data/{}/labelNeedsCorrections0719.csv'.format(each_model),index=False,encoding='utf8')\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T13:54:02.088471Z",
     "start_time": "2018-07-19T13:54:02.062153Z"
    }
   },
   "outputs": [],
   "source": [
    "CutDebt\n",
    "CutDebt: other label is: 2\n",
    "2    5803\n",
    "1    2327\n",
    "0    1784\n",
    "Name: label, dtype: int64\n",
    "total length is 9914!! Label needs to be checked length is 1516\n",
    "================================\n",
    "IDClassifier\n",
    "IDClassifier: other label is: 2\n",
    "2    4351\n",
    "1    1234\n",
    "0    1133\n",
    "Name: label, dtype: int64\n",
    "total length is 6718!! Label needs to be checked length is 748\n",
    "================================\n",
    "IfKnowDebtor\n",
    "IfKnowDebtor: other label is: 2\n",
    "2    4351\n",
    "0    1363\n",
    "1    1184\n",
    "Name: label, dtype: int64\n",
    "total length is 6898!! Label needs to be checked length is 655\n",
    "================================\n",
    "Installment\n",
    "Installment: other label is: 2\n",
    "2    5803\n",
    "1    2379\n",
    "0    1839\n",
    "Name: label, dtype: int64\n",
    "total length is 10021!! Label needs to be checked length is 1778\n",
    "================================\n",
    "ConfirmLoan\n",
    "ConfirmLoan: other label is: 2\n",
    "2    4280\n",
    "0     713\n",
    "1     548\n",
    "Name: label, dtype: int64\n",
    "total length is 5541!! Label needs to be checked length is 453\n",
    "================================\n",
    "WillingToPay\n",
    "WillingToPay: other label is: 3\n",
    "3    5464\n",
    "1    2620\n",
    "0    1778\n",
    "2    1038\n",
    "Name: label, dtype: int64\n",
    "total length is 10900!! Label needs to be checked length is 1680\n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T14:02:46.101186Z",
     "start_time": "2018-07-19T14:02:46.088087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    4902\n",
       "0    4827\n",
       "1    4728\n",
       "2    4675\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
